{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 3, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 196, "column": 0}, "map": {"version":3,"sources":["file:///Users/itwelaibomu/Desktop/code/agents-2025-dope/apps/web/convex/_generated/api.js"],"sourcesContent":["/* eslint-disable */\n/**\n * Generated `api` utility.\n *\n * THIS CODE IS AUTOMATICALLY GENERATED.\n *\n * To regenerate, run `npx convex dev`.\n * @module\n */\n\nimport { anyApi } from \"convex/server\";\n\n/**\n * A utility for referencing Convex functions in your app's API.\n *\n * Usage:\n * ```js\n * const myFunctionReference = api.myModule.myFunction;\n * ```\n */\nexport const api = anyApi;\nexport const internal = anyApi;\n"],"names":[],"mappings":"AAAA,kBAAkB,GAClB;;;;;;;CAOC;;;;;;AAED;AAAA;;AAUO,MAAM,MAAM,kKAAM;AAClB,MAAM,WAAW,kKAAM","debugId":null}},
    {"offset": {"line": 230, "column": 0}, "map": {"version":3,"sources":["file:///Users/itwelaibomu/Desktop/code/agents-2025-dope/apps/web/src/app/agentActions.ts"],"sourcesContent":["import Firecrawl from \"@mendable/firecrawl-js\";\nimport { z } from \"zod\";\n\nconst firecrawl = new Firecrawl({\n    apiKey:\n      process.env.NODE_ENV === \"development\"\n        ? process.env.NEXT_PUBLIC_FIRECRAWL_API_KEY\n        : process.env.FIRECRAWL_API_KEY,\n  });\n\nfunction quickFormatUrl(url: string): string {\n    if (!url.startsWith(\"http://\") && !url.startsWith(\"https://\")) {\n      return \"https://\" + url;\n    }\n    return url;\n}\n\nasync function analyzeWebsiteViaFirecrawl(url: string, analysisType: 'content' | 'gather-style-of-speaking') {\n\n    const formattedUrl = quickFormatUrl(url);\n\n    // Define the structured schema we want from any website with content type\n    const WebsiteSummarySchema = z.object({\n      summaryOfTheBusiness: z.string().describe(\"A summary of the business, go into detail as much as possible.\"),\n      aboutTheBusiness: z.string().describe(\"About the business; useful background for understanding the company.\"),\n      servicesOffered: z.string().describe(\"Services they offer with details.\"),\n      whereTheyServe: z.string().describe(\"Where they serve, geography/markets.\"),\n    });\n\n    // Define the structured schema we want from any website with gather-style-of-speaking type\n    const GatherStyleOfSpeakingSchema = z.object({\n      toneAndVoice: z.string().describe(\"The overall tone and voice of the website - formal, casual, professional, friendly, authoritative, conversational, etc.\"),\n      writingStyle: z.string().describe(\"The writing style characteristics - sentence structure, paragraph length, use of technical jargon, storytelling approach, etc.\"),\n      languagePatterns: z.string().describe(\"Specific language patterns, vocabulary choices, industry terminology, colloquialisms, and recurring phrases or expressions.\"),\n      communicationApproach: z.string().describe(\"How they communicate with their audience - direct vs indirect, educational vs promotional, problem-focused vs solution-focused, etc.\"),\n      emotionalTone: z.string().describe(\"The emotional undertone of the content - enthusiastic, empathetic, urgent, reassuring, confident, humble, etc.\"),\n      brandPersonality: z.string().describe(\"The personality that comes through in the writing - innovative, traditional, rebellious, trustworthy, cutting-edge, established, etc.\"),\n      rhetoricalDevices: z.string().describe(\"Use of questions, calls-to-action, testimonials, statistics, storytelling, metaphors, or other persuasive techniques.\"),\n      audienceAddressing: z.string().describe(\"How they address their audience - formal titles, first person, second person, inclusive language, industry-specific addressing, etc.\"),\n      contentStructure: z.string().describe(\"How they organize and present information - bullet points, numbered lists, headers, short vs long-form content, etc.\"),\n      examplePhrases: z.array(z.string()).describe(\"Specific example phrases, sentences, or word choices that exemplify their style of communication.\"),\n    });\n\n    let schema: z.ZodSchema;\n    let prompt: string;\n    let systemPrompt: string;\n\n    if (analysisType === 'gather-style-of-speaking') {\n      schema = GatherStyleOfSpeakingSchema;\n      prompt = \"Extract the style of speaking of the website.\";\n      systemPrompt = \"You are a helpful assistant that extracts the style of speaking of the website.\";\n    } else {\n      schema = WebsiteSummarySchema;\n      prompt = \"Extract the summary of the business, about the business, services offered, and where they serve.\";\n      systemPrompt = \"You are a helpful assistant that extracts the summary of the business, about the business, services offered, and where they serve.\";\n    }\n\n    // Use Firecrawl Extract with schema. We keep scrapeOptions lean for speed; limit is not used by extract directly.\n    const extraction = await firecrawl.extract([formattedUrl], {\n      schema: schema,\n      scrapeOptions: {\n        onlyMainContent: true,\n      },\n      prompt: prompt,\n      systemPrompt: systemPrompt,\n      showSources: true,\n      includeSubdomains: true,\n      enableWebSearch: false,\n    });\n\n    const structured = (extraction as any)?.data as z.infer<typeof WebsiteSummarySchema> | undefined;\n\n    const payload = {\n      success: true,\n      source: { url: formattedUrl, fetchedAt: new Date().toISOString() },\n      contentType: \"json\" as const,\n      // Keep a string content for backwards compatibility, but prefer `structured` downstream\n      content: structured ? JSON.stringify(structured) : \"\",\n      structured,\n    } as const;\n\n    return payload;\n}\n\nasync function deepResearchAnything(researchQuery: string, websiteUrl?: string) {\n\n  // Create completely flexible schema for ANY research topic\n  const UniversalResearchSchema = z.object({\n    query: z.string().describe(\"The research question that was answered\"),\n    keyFindings: z.string().describe(\"The main findings and insights from the research\"),\n    detailedAnalysis: z.string().describe(\"Comprehensive analysis addressing the specific query\"),\n    supporting_evidence: z.string().describe(\"Specific evidence, data, sources, and examples found during research\"),\n    conclusions: z.string().describe(\"Conclusions and insights drawn from the research\"),\n    actionableInsights: z.string().describe(\"Practical, actionable insights relevant to the query\"),\n    relatedTopics: z.string().describe(\"Related topics or areas for further research\"),\n    fullReportMarkdown: z.string().describe(\"Complete research report in well-structured Markdown format addressing the specific query\")\n  });\n\n  // If a website is provided, include it in the query, otherwise research the topic generally\n  const query = websiteUrl \n    ? `${researchQuery} - Include analysis of this website: ${quickFormatUrl(websiteUrl)}`\n    : researchQuery;\n  \n  const analysisPrompt = `${researchQuery}\n\nConduct thorough, comprehensive research to answer this query. Use all available sources and provide detailed, evidence-based analysis. Structure your response to directly address the question with supporting evidence and actionable insights.\n\nBe comprehensive and include:\n- Specific examples and data\n- Multiple perspectives when relevant  \n- Current and up-to-date information\n- Actionable conclusions\n- Clear, well-organized analysis\n\n${websiteUrl ? 'Include specific analysis of the provided website as a primary source.' : 'Research broadly using all available sources.'}`;\n\n  const systemPrompt = \"You are a senior research analyst capable of researching any topic thoroughly. Provide comprehensive, evidence-based analysis that directly addresses the research query. Be precise, detailed, and focus on actionable insights.\";\n\n  const research = await firecrawl.deepResearch(query, {\n    maxDepth: 5,\n    timeLimit: 300,\n    maxUrls: websiteUrl ? 15 : 25, // More URLs if no specific website\n    analysisPrompt: analysisPrompt,\n    systemPrompt: systemPrompt,\n    formats: [\"markdown\", \"json\"],\n    jsonOptions: {\n      schema: UniversalResearchSchema,\n      systemPrompt: \"Return comprehensive research results in valid JSON format. Address the specific research query thoroughly in each field.\",\n      prompt: \"Provide detailed, well-researched answers in each field. The fullReportMarkdown should be a complete, professional research report.\",\n    },\n  });\n\n  return research;\n\n}\n\nexport { analyzeWebsiteViaFirecrawl, deepResearchAnything };"],"names":[],"mappings":";;;;;;AAAA;AACA;;;AAEA,MAAM,YAAY,IAAI,2KAAS,CAAC;IAC5B,QACE,iHAEI;AACR;AAEF,SAAS,eAAe,GAAW;IAC/B,IAAI,CAAC,IAAI,UAAU,CAAC,cAAc,CAAC,IAAI,UAAU,CAAC,aAAa;QAC7D,OAAO,aAAa;IACtB;IACA,OAAO;AACX;AAEA,eAAe,2BAA2B,GAAW,EAAE,YAAoD;IAEvG,MAAM,eAAe,eAAe;IAEpC,0EAA0E;IAC1E,MAAM,uBAAuB,yKAAC,CAAC,MAAM,CAAC;QACpC,sBAAsB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAC1C,kBAAkB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACtC,iBAAiB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACrC,gBAAgB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACtC;IAEA,2FAA2F;IAC3F,MAAM,8BAA8B,yKAAC,CAAC,MAAM,CAAC;QAC3C,cAAc,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAClC,cAAc,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAClC,kBAAkB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACtC,uBAAuB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAC3C,eAAe,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACnC,kBAAkB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACtC,mBAAmB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACvC,oBAAoB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACxC,kBAAkB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACtC,gBAAgB,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,CAAC;IAC/C;IAEA,IAAI;IACJ,IAAI;IACJ,IAAI;IAEJ,IAAI,iBAAiB,4BAA4B;QAC/C,SAAS;QACT,SAAS;QACT,eAAe;IACjB,OAAO;QACL,SAAS;QACT,SAAS;QACT,eAAe;IACjB;IAEA,kHAAkH;IAClH,MAAM,aAAa,MAAM,UAAU,OAAO,CAAC;QAAC;KAAa,EAAE;QACzD,QAAQ;QACR,eAAe;YACb,iBAAiB;QACnB;QACA,QAAQ;QACR,cAAc;QACd,aAAa;QACb,mBAAmB;QACnB,iBAAiB;IACnB;IAEA,MAAM,aAAc,YAAoB;IAExC,MAAM,UAAU;QACd,SAAS;QACT,QAAQ;YAAE,KAAK;YAAc,WAAW,IAAI,OAAO,WAAW;QAAG;QACjE,aAAa;QACb,wFAAwF;QACxF,SAAS,aAAa,KAAK,SAAS,CAAC,cAAc;QACnD;IACF;IAEA,OAAO;AACX;AAEA,eAAe,qBAAqB,aAAqB,EAAE,UAAmB;IAE5E,2DAA2D;IAC3D,MAAM,0BAA0B,yKAAC,CAAC,MAAM,CAAC;QACvC,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAC3B,aAAa,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACjC,kBAAkB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACtC,qBAAqB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACzC,aAAa,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACjC,oBAAoB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACxC,eAAe,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACnC,oBAAoB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC1C;IAEA,4FAA4F;IAC5F,MAAM,QAAQ,aACV,GAAG,cAAc,qCAAqC,EAAE,eAAe,aAAa,GACpF;IAEJ,MAAM,iBAAiB,GAAG,cAAc;;;;;;;;;;;AAW1C,EAAE,aAAa,2EAA2E,iDAAiD;IAEzI,MAAM,eAAe;IAErB,MAAM,WAAW,MAAM,UAAU,YAAY,CAAC,OAAO;QACnD,UAAU;QACV,WAAW;QACX,SAAS,aAAa,KAAK;QAC3B,gBAAgB;QAChB,cAAc;QACd,SAAS;YAAC;YAAY;SAAO;QAC7B,aAAa;YACX,QAAQ;YACR,cAAc;YACd,QAAQ;QACV;IACF;IAEA,OAAO;AAET","debugId":null}},
    {"offset": {"line": 361, "column": 0}, "map": {"version":3,"sources":["file:///Users/itwelaibomu/Desktop/code/agents-2025-dope/apps/web/src/services/pineconeService.ts"],"sourcesContent":["import { Pinecone } from '@pinecone-database/pinecone';\nimport dotenv from 'dotenv';\nimport { EmployeeDataInput, TranscriptDataInput } from '../types/metadata';\n\n// Employee data interface based on the metadata types\ninterface EmployeeData {\n  employeeId: string;\n  name: string;\n  organization: string;\n  position: string;\n  reportsTo: string;\n  gender?: string | null;\n  assessmentDate: string;\n  all34: string[];\n  leadDomain: 'Executing' | 'Influencing' | 'Relationship Building' | 'Strategic Thinking';\n  themeDomains: {\n    Executing: string[];\n    Influencing: string[];\n    RelationshipBuilding: string[];\n    StrategyThinking: string[];\n  };\n  bestCollabWith: string;\n  communicationTips: string;\n  howToCoach: string;\n  motivators: string[];\n  demotivators: string[];\n  watchouts: string;\n  evidenceQuotes: Array<{\n    quote: string;\n    section: string;\n  }>;\n  sourceDocUrl?: string | null;\n  sourceProvenance?: string | null;\n}\n\ndotenv.config();\n\n// Get API key from environment variables\nexport const getApiKey = () => {\n  const apiKey = process.env.NODE_ENV === 'production' ? process.env.PINECONE_API_KEY : process.env.NEXT_PUBLIC_PINECONE_API_KEY;\n\n  return apiKey || '';\n};\n\nconst pc = new Pinecone({\n  apiKey: getApiKey()\n});\n\nexport { pc };\n\n// Create a new index with embeddings model\nexport async function createIndex(indexName: string) {\n  try {\n    await pc.createIndexForModel({\n      name: indexName,\n      cloud: 'aws',\n      region: 'us-east-1',\n      embed: {\n        model: 'llama-text-embed-v2',\n        fieldMap: { text: 'chunk_text' },\n      },\n      waitUntilReady: true,\n    });\n    return { success: true };\n  } catch (error) {\n    console.error('Error creating index:', error);\n    throw new Error(`Failed to create index: ${error instanceof Error ? error.message : 'Unknown error'}`);\n  }\n}\n\n// Helper function to estimate metadata size in bytes\nfunction estimateMetadataSize(metadata: Record<string, any>): number {\n  return JSON.stringify(metadata).length * 2; // Rough estimate (UTF-16)\n}\n\n// Helper function to split large metadata into smaller chunks\nfunction splitMetadata(metadata: Record<string, any>, maxSizeBytes: number = 30000): Record<string, any>[] {\n  const metadataStr = JSON.stringify(metadata);\n  const estimatedSize = metadataStr.length * 2;\n\n  if (estimatedSize <= maxSizeBytes) {\n    return [metadata];\n  }\n\n  // Split large arrays and strings\n  const chunks: Record<string, any>[] = [];\n  const baseMetadata = { ...metadata };\n\n  // Handle large array fields\n  const arrayFields = ['participants', 'action_items', 'concepts_discussed', 'key_topics'];\n\n  for (const field of arrayFields) {\n    if (Array.isArray(baseMetadata[field]) && baseMetadata[field].length > 10) {\n      const items = baseMetadata[field];\n      const chunkSize = Math.ceil(items.length / Math.ceil(estimatedSize / maxSizeBytes));\n\n      for (let i = 0; i < items.length; i += chunkSize) {\n        const chunk = {\n          ...baseMetadata,\n          [field]: items.slice(i, i + chunkSize),\n          chunk_index: Math.floor(i / chunkSize),\n          total_chunks: Math.ceil(items.length / chunkSize)\n        };\n        chunks.push(chunk);\n      }\n\n      // Remove the original field from base metadata\n      delete baseMetadata[field];\n    }\n  }\n\n  // If no chunks were created, create one with reduced metadata\n  if (chunks.length === 0) {\n    const reducedMetadata = { ...baseMetadata };\n    // Remove or truncate large string fields\n    if (reducedMetadata.summary && reducedMetadata.summary.length > 1000) {\n      reducedMetadata.summary = reducedMetadata.summary.substring(0, 1000) + '...';\n    }\n    chunks.push(reducedMetadata);\n  }\n\n  return chunks;\n}\n\n// Helper function to chunk large content\nfunction chunkContent(content: string, maxChunkSize: number = 2000): string[] {\n  if (content.length <= maxChunkSize) {\n    return [content];\n  }\n\n  const chunks: string[] = [];\n  const sentences = content.split(/[.!?]+/).filter(s => s.trim().length > 0);\n  let currentChunk = '';\n\n  for (const sentence of sentences) {\n    const trimmedSentence = sentence.trim();\n    if (currentChunk.length + trimmedSentence.length + 1 <= maxChunkSize) {\n      currentChunk += (currentChunk ? '. ' : '') + trimmedSentence;\n    } else {\n      if (currentChunk) {\n        chunks.push(currentChunk + '.');\n      }\n      currentChunk = trimmedSentence;\n    }\n  }\n\n  if (currentChunk) {\n    chunks.push(currentChunk + '.');\n  }\n\n  return chunks;\n}\n\n// Add data to an index with automatic chunking for large content\nexport async function addToIndex(indexName: string, data: { title: string; content: string; metadata?: Record<string, any> }) {\n  try {\n    const index = pc.index(indexName);\n\n    // Chunk the content if it's too large\n    const contentChunks = chunkContent(data.content);\n\n    // Split metadata if it's too large\n    const metadataChunks = data.metadata ? splitMetadata(data.metadata) : [{}];\n\n    const records = [];\n\n    // Create records for each combination of content and metadata chunks\n    for (let i = 0; i < contentChunks.length; i++) {\n      for (let j = 0; j < metadataChunks.length; j++) {\n        const id = `${Date.now()}-${Math.random().toString(36).substr(2, 9)}-${i}-${j}`;\n\n        const record: any = {\n          _id: id,\n          chunk_text: contentChunks[i],\n          title: data.title,\n          content_chunk_index: i,\n          total_content_chunks: contentChunks.length,\n          ...metadataChunks[j],\n          created_at: new Date().toISOString(),\n        };\n\n        // Check if this record would be too large\n        const estimatedSize = estimateMetadataSize(record);\n        if (estimatedSize > 35000) { // Leave some buffer\n          console.warn(`Record ${id} is still too large (${estimatedSize} bytes), further reducing...`);\n          // Further reduce the record\n          record.chunk_text = record.chunk_text.substring(0, 1000) + '...';\n          if (record.summary) {\n            record.summary = record.summary.substring(0, 500) + '...';\n          }\n        }\n\n        records.push(record);\n      }\n    }\n\n    // Batch upsert records\n    const batchSize = 100; // Pinecone batch limit\n    for (let i = 0; i < records.length; i += batchSize) {\n      const batch = records.slice(i, i + batchSize);\n      await index.upsertRecords(batch);\n    }\n\n    return { success: true, id: records[0]._id, totalChunks: records.length };\n  } catch (error) {\n    console.error('Error adding to index:', error);\n    throw new Error(`Failed to add to index: ${error instanceof Error ? error.message : 'Unknown error'}`);\n  }\n}\n\n// Specialized function for adding employee data to Pinecone\nexport async function addEmployeeDataToIndex(indexName: string, data: EmployeeDataInput) {\n  try {\n    const index = pc.index(indexName);\n    const { employeeData, tags = [], source } = data;\n\n    // Create searchable content from employee data\n    const searchableContent = createEmployeeSearchableContent(employeeData);\n\n    // Chunk the content if it's too large\n    const contentChunks = chunkContent(searchableContent);\n\n    const records = [];\n\n    // Create records for each content chunk\n    for (let i = 0; i < contentChunks.length; i++) {\n      const id = `${employeeData.employeeId}-${Date.now()}-${i}`;\n\n      const record: any = {\n        _id: id,\n        chunk_text: contentChunks[i],\n        title: `${employeeData.name} - ${employeeData.position}`,\n        content_chunk_index: i,\n        total_content_chunks: contentChunks.length,\n\n        // Employee-specific metadata\n        employeeId: employeeData.employeeId,\n        name: employeeData.name,\n        organization: employeeData.organization,\n        position: employeeData.position,\n        reportsTo: employeeData.reportsTo,\n        gender: employeeData.gender,\n        assessmentDate: employeeData.assessmentDate,\n        leadDomain: employeeData.leadDomain,\n\n        // Arrays as comma-separated strings for better searchability\n        all34: Array.isArray(employeeData.all34) ? employeeData.all34.join(', ') : employeeData.all34,\n        motivators: Array.isArray(employeeData.motivators) ? employeeData.motivators.join(', ') : employeeData.motivators,\n        demotivators: Array.isArray(employeeData.demotivators) ? employeeData.demotivators.join(', ') : employeeData.demotivators,\n\n        // Text fields\n        bestCollabWith: employeeData.bestCollabWith,\n        communicationTips: employeeData.communicationTips,\n        howToCoach: employeeData.howToCoach,\n        watchouts: employeeData.watchouts,\n\n        // Theme domains as JSON strings\n        themeDomains: JSON.stringify(employeeData.themeDomains),\n        evidenceQuotes: JSON.stringify(employeeData.evidenceQuotes),\n\n        // Source information\n        sourceDocUrl: employeeData.sourceDocUrl,\n        sourceProvenance: employeeData.sourceProvenance,\n\n        // Additional metadata\n        tags: Array.isArray(tags) ? tags.join(', ') : tags,\n        source: source,\n        created_at: new Date().toISOString(),\n        data_type: 'employee_profile'\n      };\n\n      // Check if this record would be too large\n      const estimatedSize = estimateMetadataSize(record);\n      if (estimatedSize > 35000) { // Leave some buffer\n        console.warn(`Record ${id} is still too large (${estimatedSize} bytes), further reducing...`);\n        // Further reduce the record\n        record.chunk_text = record.chunk_text.substring(0, 1000) + '...';\n        if (record.bestCollabWith) {\n          record.bestCollabWith = record.bestCollabWith.substring(0, 500) + '...';\n        }\n      }\n\n      records.push(record);\n    }\n\n    // Batch upsert records\n    const batchSize = 100; // Pinecone batch limit\n    for (let i = 0; i < records.length; i += batchSize) {\n      const batch = records.slice(i, i + batchSize);\n      await index.upsertRecords(batch);\n    }\n\n    return { success: true, id: records[0]._id, totalChunks: records.length };\n  } catch (error) {\n    console.error('Error adding employee data to index:', error);\n    throw new Error(`Failed to add employee data to index: ${error instanceof Error ? error.message : 'Unknown error'}`);\n  }\n}\n\n// Specialized function for adding transcript data to Pinecone\nexport async function addTranscriptDataToIndex(indexName: string, data: TranscriptDataInput) {\n  try {\n    const index = pc.index(indexName);\n    const { transcriptData, tags = [], source } = data;\n\n    const searchableContent = createTranscriptSearchableContent(transcriptData);\n    const contentChunks = chunkContent(searchableContent);\n    const records: any[] = [];\n\n    for (let i = 0; i < contentChunks.length; i++) {\n      const id = `${transcriptData.date || 'unknown-date'}-${Date.now()}-${i}`;\n      const record: any = {\n        _id: id,\n        chunk_text: contentChunks[i],\n        title: `${transcriptData.title || 'Transcript'}${transcriptData.date ? ' - ' + transcriptData.date : ''}`,\n        content_chunk_index: i,\n        total_content_chunks: contentChunks.length,\n\n        meetingType: transcriptData.meetingType,\n        duration: transcriptData.duration,\n        participants: Array.isArray(transcriptData.participants) ? transcriptData.participants.join(', ') : transcriptData.participants,\n        location: transcriptData.location,\n        department: transcriptData.department,\n        confidentialityLevel: transcriptData.confidentialityLevel,\n        action_items: Array.isArray(transcriptData.action_items) ? transcriptData.action_items.join(', ') : transcriptData.action_items,\n        concepts_discussed: Array.isArray(transcriptData.concepts_discussed) ? transcriptData.concepts_discussed.join(', ') : transcriptData.concepts_discussed,\n        date: transcriptData.date,\n        key_topics: Array.isArray(transcriptData.key_topics) ? transcriptData.key_topics.join(', ') : transcriptData.key_topics,\n        summary: transcriptData.summary,\n\n        tags: Array.isArray(tags) ? tags.join(', ') : tags,\n        source: source,\n        created_at: new Date().toISOString(),\n        data_type: 'transcript'\n      };\n\n      const estimatedSize = estimateMetadataSize(record);\n      if (estimatedSize > 35000) {\n        console.warn(`Transcript record ${id} is too large (${estimatedSize} bytes), reducing...`);\n        record.chunk_text = record.chunk_text.substring(0, 1000) + '...';\n        if (record.summary && typeof record.summary === 'string') {\n          record.summary = record.summary.substring(0, 500) + '...';\n        }\n      }\n\n      records.push(record);\n    }\n\n    const batchSize = 100;\n    for (let i = 0; i < records.length; i += batchSize) {\n      const batch = records.slice(i, i + batchSize);\n      await index.upsertRecords(batch);\n    }\n\n    return { success: true, id: records[0]._id, totalChunks: records.length };\n  } catch (error) {\n    console.error('Error adding transcript data to index:', error);\n    throw new Error(`Failed to add transcript data to index: ${error instanceof Error ? error.message : 'Unknown error'}`);\n  }\n}\n\n// Helper function to create searchable content from employee data\nfunction createEmployeeSearchableContent(employeeData: EmployeeData): string {\n  const strengths = Array.isArray(employeeData.all34) ? employeeData.all34.join(', ') : employeeData.all34;\n  const motivators = Array.isArray(employeeData.motivators) ? employeeData.motivators.join(', ') : employeeData.motivators;\n  const demotivators = Array.isArray(employeeData.demotivators) ? employeeData.demotivators.join(', ') : employeeData.demotivators;\n\n  return `Employee Profile: ${employeeData.name}\nPosition: ${employeeData.position}\nOrganization: ${employeeData.organization}\nReports To: ${employeeData.reportsTo}\nLead Domain: ${employeeData.leadDomain}\nAssessment Date: ${employeeData.assessmentDate}\n\nStrengths: ${strengths}\n\nBest Collaboration: ${employeeData.bestCollabWith}\n\nCommunication Tips: ${employeeData.communicationTips}\n\nHow to Coach: ${employeeData.howToCoach}\n\nMotivators: ${motivators}\n\nDemotivators: ${demotivators}\n\nWatchouts: ${employeeData.watchouts}\n\nTheme Domains: ${JSON.stringify(employeeData.themeDomains)}\n\nEvidence Quotes: ${JSON.stringify(employeeData.evidenceQuotes)}`;\n}\n\nfunction createTranscriptSearchableContent(transcriptData: import('../types/metadata').TranscriptMetadata): string {\n  const participants = Array.isArray(transcriptData.participants) ? transcriptData.participants.join(', ') : transcriptData.participants;\n  const actionItems = Array.isArray(transcriptData.action_items) ? transcriptData.action_items.join('; ') : transcriptData.action_items;\n  const conceptsDiscussed = Array.isArray(transcriptData.concepts_discussed) ? transcriptData.concepts_discussed.join('; ') : transcriptData.concepts_discussed;\n  const keyTopics = Array.isArray(transcriptData.key_topics) ? transcriptData.key_topics.join('; ') : transcriptData.key_topics;\n\n  return `Transcript Summary\nMeeting Type: ${transcriptData.meetingType || 'N/A'}\nDate: ${transcriptData.date || 'N/A'}\nDuration: ${typeof transcriptData.duration === 'number' ? `${transcriptData.duration} min` : 'N/A'}\nParticipants: ${participants || 'N/A'}\nLocation: ${transcriptData.location || 'N/A'}\nDepartment: ${transcriptData.department || 'N/A'}\nConfidentiality: ${transcriptData.confidentialityLevel || 'N/A'}\n\nKey Topics: ${keyTopics || 'N/A'}\nConcepts Discussed: ${conceptsDiscussed || 'N/A'}\nAction Items: ${actionItems || 'N/A'}\n\nSummary: ${transcriptData.summary || 'N/A'}`;\n}\n\n// List existing indexes\nexport async function listIndexesFromPinecone() {\n  try {\n    const indexes = await pc.listIndexes();\n    return indexes;\n  } catch (error) {\n    console.error('Error listing indexes:', error);\n    throw new Error(`Failed to list indexes: ${error instanceof Error ? error.message : 'Unknown error'}`);\n  }\n}\n\n\n// Semantic search using query text on an index with integrated embeddings\nexport async function semanticSearch(\n  indexName: string,\n  params: { query: string; topK?: number; namespace?: string; fields?: string[] }\n) {\n  try {\n\n    const index = pc.index(indexName);\n    const targetNamespace = (params.namespace && params.namespace.length > 0)\n      ? params.namespace\n      : '__default__';\n    const namespace = index.namespace(targetNamespace);\n\n    const response = await namespace.searchRecords({\n      query: {\n        topK: params.topK ?? 5,\n        inputs: { text: params.query },\n      },\n      // If fields are not specified, Pinecone returns all fields\n      fields: params.fields && params.fields.length > 0 ? params.fields : undefined,\n    });\n\n    return response;\n  } catch (error) {\n    console.error('Error performing semantic search:', error);\n    throw new Error(`Failed to perform semantic search: ${error instanceof Error ? error.message : 'Unknown error'}`);\n  }\n}\n\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;AAAA;AACA;;;AAkCA,kJAAM,CAAC,MAAM;AAGN,MAAM,YAAY;IACvB,MAAM,SAAS,sCAAwC;IAEvD,OAAO,UAAU;AACnB;AAEA,MAAM,KAAK,IAAI,iLAAQ,CAAC;IACtB,QAAQ;AACV;;AAKO,eAAe,YAAY,SAAiB;IACjD,IAAI;QACF,MAAM,GAAG,mBAAmB,CAAC;YAC3B,MAAM;YACN,OAAO;YACP,QAAQ;YACR,OAAO;gBACL,OAAO;gBACP,UAAU;oBAAE,MAAM;gBAAa;YACjC;YACA,gBAAgB;QAClB;QACA,OAAO;YAAE,SAAS;QAAK;IACzB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,yBAAyB;QACvC,MAAM,IAAI,MAAM,CAAC,wBAAwB,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,iBAAiB;IACvG;AACF;AAEA,qDAAqD;AACrD,SAAS,qBAAqB,QAA6B;IACzD,OAAO,KAAK,SAAS,CAAC,UAAU,MAAM,GAAG,GAAG,0BAA0B;AACxE;AAEA,8DAA8D;AAC9D,SAAS,cAAc,QAA6B,EAAE,eAAuB,KAAK;IAChF,MAAM,cAAc,KAAK,SAAS,CAAC;IACnC,MAAM,gBAAgB,YAAY,MAAM,GAAG;IAE3C,IAAI,iBAAiB,cAAc;QACjC,OAAO;YAAC;SAAS;IACnB;IAEA,iCAAiC;IACjC,MAAM,SAAgC,EAAE;IACxC,MAAM,eAAe;QAAE,GAAG,QAAQ;IAAC;IAEnC,4BAA4B;IAC5B,MAAM,cAAc;QAAC;QAAgB;QAAgB;QAAsB;KAAa;IAExF,KAAK,MAAM,SAAS,YAAa;QAC/B,IAAI,MAAM,OAAO,CAAC,YAAY,CAAC,MAAM,KAAK,YAAY,CAAC,MAAM,CAAC,MAAM,GAAG,IAAI;YACzE,MAAM,QAAQ,YAAY,CAAC,MAAM;YACjC,MAAM,YAAY,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,KAAK,IAAI,CAAC,gBAAgB;YAErE,IAAK,IAAI,IAAI,GAAG,IAAI,MAAM,MAAM,EAAE,KAAK,UAAW;gBAChD,MAAM,QAAQ;oBACZ,GAAG,YAAY;oBACf,CAAC,MAAM,EAAE,MAAM,KAAK,CAAC,GAAG,IAAI;oBAC5B,aAAa,KAAK,KAAK,CAAC,IAAI;oBAC5B,cAAc,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG;gBACzC;gBACA,OAAO,IAAI,CAAC;YACd;YAEA,+CAA+C;YAC/C,OAAO,YAAY,CAAC,MAAM;QAC5B;IACF;IAEA,8DAA8D;IAC9D,IAAI,OAAO,MAAM,KAAK,GAAG;QACvB,MAAM,kBAAkB;YAAE,GAAG,YAAY;QAAC;QAC1C,yCAAyC;QACzC,IAAI,gBAAgB,OAAO,IAAI,gBAAgB,OAAO,CAAC,MAAM,GAAG,MAAM;YACpE,gBAAgB,OAAO,GAAG,gBAAgB,OAAO,CAAC,SAAS,CAAC,GAAG,QAAQ;QACzE;QACA,OAAO,IAAI,CAAC;IACd;IAEA,OAAO;AACT;AAEA,yCAAyC;AACzC,SAAS,aAAa,OAAe,EAAE,eAAuB,IAAI;IAChE,IAAI,QAAQ,MAAM,IAAI,cAAc;QAClC,OAAO;YAAC;SAAQ;IAClB;IAEA,MAAM,SAAmB,EAAE;IAC3B,MAAM,YAAY,QAAQ,KAAK,CAAC,UAAU,MAAM,CAAC,CAAA,IAAK,EAAE,IAAI,GAAG,MAAM,GAAG;IACxE,IAAI,eAAe;IAEnB,KAAK,MAAM,YAAY,UAAW;QAChC,MAAM,kBAAkB,SAAS,IAAI;QACrC,IAAI,aAAa,MAAM,GAAG,gBAAgB,MAAM,GAAG,KAAK,cAAc;YACpE,gBAAgB,CAAC,eAAe,OAAO,EAAE,IAAI;QAC/C,OAAO;YACL,IAAI,cAAc;gBAChB,OAAO,IAAI,CAAC,eAAe;YAC7B;YACA,eAAe;QACjB;IACF;IAEA,IAAI,cAAc;QAChB,OAAO,IAAI,CAAC,eAAe;IAC7B;IAEA,OAAO;AACT;AAGO,eAAe,WAAW,SAAiB,EAAE,IAAwE;IAC1H,IAAI;QACF,MAAM,QAAQ,GAAG,KAAK,CAAC;QAEvB,sCAAsC;QACtC,MAAM,gBAAgB,aAAa,KAAK,OAAO;QAE/C,mCAAmC;QACnC,MAAM,iBAAiB,KAAK,QAAQ,GAAG,cAAc,KAAK,QAAQ,IAAI;YAAC,CAAC;SAAE;QAE1E,MAAM,UAAU,EAAE;QAElB,qEAAqE;QACrE,IAAK,IAAI,IAAI,GAAG,IAAI,cAAc,MAAM,EAAE,IAAK;YAC7C,IAAK,IAAI,IAAI,GAAG,IAAI,eAAe,MAAM,EAAE,IAAK;gBAC9C,MAAM,KAAK,GAAG,KAAK,GAAG,GAAG,CAAC,EAAE,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,MAAM,CAAC,GAAG,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,GAAG;gBAE/E,MAAM,SAAc;oBAClB,KAAK;oBACL,YAAY,aAAa,CAAC,EAAE;oBAC5B,OAAO,KAAK,KAAK;oBACjB,qBAAqB;oBACrB,sBAAsB,cAAc,MAAM;oBAC1C,GAAG,cAAc,CAAC,EAAE;oBACpB,YAAY,IAAI,OAAO,WAAW;gBACpC;gBAEA,0CAA0C;gBAC1C,MAAM,gBAAgB,qBAAqB;gBAC3C,IAAI,gBAAgB,OAAO;oBACzB,QAAQ,IAAI,CAAC,CAAC,OAAO,EAAE,GAAG,qBAAqB,EAAE,cAAc,4BAA4B,CAAC;oBAC5F,4BAA4B;oBAC5B,OAAO,UAAU,GAAG,OAAO,UAAU,CAAC,SAAS,CAAC,GAAG,QAAQ;oBAC3D,IAAI,OAAO,OAAO,EAAE;wBAClB,OAAO,OAAO,GAAG,OAAO,OAAO,CAAC,SAAS,CAAC,GAAG,OAAO;oBACtD;gBACF;gBAEA,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,uBAAuB;QACvB,MAAM,YAAY,KAAK,uBAAuB;QAC9C,IAAK,IAAI,IAAI,GAAG,IAAI,QAAQ,MAAM,EAAE,KAAK,UAAW;YAClD,MAAM,QAAQ,QAAQ,KAAK,CAAC,GAAG,IAAI;YACnC,MAAM,MAAM,aAAa,CAAC;QAC5B;QAEA,OAAO;YAAE,SAAS;YAAM,IAAI,OAAO,CAAC,EAAE,CAAC,GAAG;YAAE,aAAa,QAAQ,MAAM;QAAC;IAC1E,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0BAA0B;QACxC,MAAM,IAAI,MAAM,CAAC,wBAAwB,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,iBAAiB;IACvG;AACF;AAGO,eAAe,uBAAuB,SAAiB,EAAE,IAAuB;IACrF,IAAI;QACF,MAAM,QAAQ,GAAG,KAAK,CAAC;QACvB,MAAM,EAAE,YAAY,EAAE,OAAO,EAAE,EAAE,MAAM,EAAE,GAAG;QAE5C,+CAA+C;QAC/C,MAAM,oBAAoB,gCAAgC;QAE1D,sCAAsC;QACtC,MAAM,gBAAgB,aAAa;QAEnC,MAAM,UAAU,EAAE;QAElB,wCAAwC;QACxC,IAAK,IAAI,IAAI,GAAG,IAAI,cAAc,MAAM,EAAE,IAAK;YAC7C,MAAM,KAAK,GAAG,aAAa,UAAU,CAAC,CAAC,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,GAAG;YAE1D,MAAM,SAAc;gBAClB,KAAK;gBACL,YAAY,aAAa,CAAC,EAAE;gBAC5B,OAAO,GAAG,aAAa,IAAI,CAAC,GAAG,EAAE,aAAa,QAAQ,EAAE;gBACxD,qBAAqB;gBACrB,sBAAsB,cAAc,MAAM;gBAE1C,6BAA6B;gBAC7B,YAAY,aAAa,UAAU;gBACnC,MAAM,aAAa,IAAI;gBACvB,cAAc,aAAa,YAAY;gBACvC,UAAU,aAAa,QAAQ;gBAC/B,WAAW,aAAa,SAAS;gBACjC,QAAQ,aAAa,MAAM;gBAC3B,gBAAgB,aAAa,cAAc;gBAC3C,YAAY,aAAa,UAAU;gBAEnC,6DAA6D;gBAC7D,OAAO,MAAM,OAAO,CAAC,aAAa,KAAK,IAAI,aAAa,KAAK,CAAC,IAAI,CAAC,QAAQ,aAAa,KAAK;gBAC7F,YAAY,MAAM,OAAO,CAAC,aAAa,UAAU,IAAI,aAAa,UAAU,CAAC,IAAI,CAAC,QAAQ,aAAa,UAAU;gBACjH,cAAc,MAAM,OAAO,CAAC,aAAa,YAAY,IAAI,aAAa,YAAY,CAAC,IAAI,CAAC,QAAQ,aAAa,YAAY;gBAEzH,cAAc;gBACd,gBAAgB,aAAa,cAAc;gBAC3C,mBAAmB,aAAa,iBAAiB;gBACjD,YAAY,aAAa,UAAU;gBACnC,WAAW,aAAa,SAAS;gBAEjC,gCAAgC;gBAChC,cAAc,KAAK,SAAS,CAAC,aAAa,YAAY;gBACtD,gBAAgB,KAAK,SAAS,CAAC,aAAa,cAAc;gBAE1D,qBAAqB;gBACrB,cAAc,aAAa,YAAY;gBACvC,kBAAkB,aAAa,gBAAgB;gBAE/C,sBAAsB;gBACtB,MAAM,MAAM,OAAO,CAAC,QAAQ,KAAK,IAAI,CAAC,QAAQ;gBAC9C,QAAQ;gBACR,YAAY,IAAI,OAAO,WAAW;gBAClC,WAAW;YACb;YAEA,0CAA0C;YAC1C,MAAM,gBAAgB,qBAAqB;YAC3C,IAAI,gBAAgB,OAAO;gBACzB,QAAQ,IAAI,CAAC,CAAC,OAAO,EAAE,GAAG,qBAAqB,EAAE,cAAc,4BAA4B,CAAC;gBAC5F,4BAA4B;gBAC5B,OAAO,UAAU,GAAG,OAAO,UAAU,CAAC,SAAS,CAAC,GAAG,QAAQ;gBAC3D,IAAI,OAAO,cAAc,EAAE;oBACzB,OAAO,cAAc,GAAG,OAAO,cAAc,CAAC,SAAS,CAAC,GAAG,OAAO;gBACpE;YACF;YAEA,QAAQ,IAAI,CAAC;QACf;QAEA,uBAAuB;QACvB,MAAM,YAAY,KAAK,uBAAuB;QAC9C,IAAK,IAAI,IAAI,GAAG,IAAI,QAAQ,MAAM,EAAE,KAAK,UAAW;YAClD,MAAM,QAAQ,QAAQ,KAAK,CAAC,GAAG,IAAI;YACnC,MAAM,MAAM,aAAa,CAAC;QAC5B;QAEA,OAAO;YAAE,SAAS;YAAM,IAAI,OAAO,CAAC,EAAE,CAAC,GAAG;YAAE,aAAa,QAAQ,MAAM;QAAC;IAC1E,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,wCAAwC;QACtD,MAAM,IAAI,MAAM,CAAC,sCAAsC,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,iBAAiB;IACrH;AACF;AAGO,eAAe,yBAAyB,SAAiB,EAAE,IAAyB;IACzF,IAAI;QACF,MAAM,QAAQ,GAAG,KAAK,CAAC;QACvB,MAAM,EAAE,cAAc,EAAE,OAAO,EAAE,EAAE,MAAM,EAAE,GAAG;QAE9C,MAAM,oBAAoB,kCAAkC;QAC5D,MAAM,gBAAgB,aAAa;QACnC,MAAM,UAAiB,EAAE;QAEzB,IAAK,IAAI,IAAI,GAAG,IAAI,cAAc,MAAM,EAAE,IAAK;YAC7C,MAAM,KAAK,GAAG,eAAe,IAAI,IAAI,eAAe,CAAC,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,GAAG;YACxE,MAAM,SAAc;gBAClB,KAAK;gBACL,YAAY,aAAa,CAAC,EAAE;gBAC5B,OAAO,GAAG,eAAe,KAAK,IAAI,eAAe,eAAe,IAAI,GAAG,QAAQ,eAAe,IAAI,GAAG,IAAI;gBACzG,qBAAqB;gBACrB,sBAAsB,cAAc,MAAM;gBAE1C,aAAa,eAAe,WAAW;gBACvC,UAAU,eAAe,QAAQ;gBACjC,cAAc,MAAM,OAAO,CAAC,eAAe,YAAY,IAAI,eAAe,YAAY,CAAC,IAAI,CAAC,QAAQ,eAAe,YAAY;gBAC/H,UAAU,eAAe,QAAQ;gBACjC,YAAY,eAAe,UAAU;gBACrC,sBAAsB,eAAe,oBAAoB;gBACzD,cAAc,MAAM,OAAO,CAAC,eAAe,YAAY,IAAI,eAAe,YAAY,CAAC,IAAI,CAAC,QAAQ,eAAe,YAAY;gBAC/H,oBAAoB,MAAM,OAAO,CAAC,eAAe,kBAAkB,IAAI,eAAe,kBAAkB,CAAC,IAAI,CAAC,QAAQ,eAAe,kBAAkB;gBACvJ,MAAM,eAAe,IAAI;gBACzB,YAAY,MAAM,OAAO,CAAC,eAAe,UAAU,IAAI,eAAe,UAAU,CAAC,IAAI,CAAC,QAAQ,eAAe,UAAU;gBACvH,SAAS,eAAe,OAAO;gBAE/B,MAAM,MAAM,OAAO,CAAC,QAAQ,KAAK,IAAI,CAAC,QAAQ;gBAC9C,QAAQ;gBACR,YAAY,IAAI,OAAO,WAAW;gBAClC,WAAW;YACb;YAEA,MAAM,gBAAgB,qBAAqB;YAC3C,IAAI,gBAAgB,OAAO;gBACzB,QAAQ,IAAI,CAAC,CAAC,kBAAkB,EAAE,GAAG,eAAe,EAAE,cAAc,oBAAoB,CAAC;gBACzF,OAAO,UAAU,GAAG,OAAO,UAAU,CAAC,SAAS,CAAC,GAAG,QAAQ;gBAC3D,IAAI,OAAO,OAAO,IAAI,OAAO,OAAO,OAAO,KAAK,UAAU;oBACxD,OAAO,OAAO,GAAG,OAAO,OAAO,CAAC,SAAS,CAAC,GAAG,OAAO;gBACtD;YACF;YAEA,QAAQ,IAAI,CAAC;QACf;QAEA,MAAM,YAAY;QAClB,IAAK,IAAI,IAAI,GAAG,IAAI,QAAQ,MAAM,EAAE,KAAK,UAAW;YAClD,MAAM,QAAQ,QAAQ,KAAK,CAAC,GAAG,IAAI;YACnC,MAAM,MAAM,aAAa,CAAC;QAC5B;QAEA,OAAO;YAAE,SAAS;YAAM,IAAI,OAAO,CAAC,EAAE,CAAC,GAAG;YAAE,aAAa,QAAQ,MAAM;QAAC;IAC1E,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0CAA0C;QACxD,MAAM,IAAI,MAAM,CAAC,wCAAwC,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,iBAAiB;IACvH;AACF;AAEA,kEAAkE;AAClE,SAAS,gCAAgC,YAA0B;IACjE,MAAM,YAAY,MAAM,OAAO,CAAC,aAAa,KAAK,IAAI,aAAa,KAAK,CAAC,IAAI,CAAC,QAAQ,aAAa,KAAK;IACxG,MAAM,aAAa,MAAM,OAAO,CAAC,aAAa,UAAU,IAAI,aAAa,UAAU,CAAC,IAAI,CAAC,QAAQ,aAAa,UAAU;IACxH,MAAM,eAAe,MAAM,OAAO,CAAC,aAAa,YAAY,IAAI,aAAa,YAAY,CAAC,IAAI,CAAC,QAAQ,aAAa,YAAY;IAEhI,OAAO,CAAC,kBAAkB,EAAE,aAAa,IAAI,CAAC;UACtC,EAAE,aAAa,QAAQ,CAAC;cACpB,EAAE,aAAa,YAAY,CAAC;YAC9B,EAAE,aAAa,SAAS,CAAC;aACxB,EAAE,aAAa,UAAU,CAAC;iBACtB,EAAE,aAAa,cAAc,CAAC;;WAEpC,EAAE,UAAU;;oBAEH,EAAE,aAAa,cAAc,CAAC;;oBAE9B,EAAE,aAAa,iBAAiB,CAAC;;cAEvC,EAAE,aAAa,UAAU,CAAC;;YAE5B,EAAE,WAAW;;cAEX,EAAE,aAAa;;WAElB,EAAE,aAAa,SAAS,CAAC;;eAErB,EAAE,KAAK,SAAS,CAAC,aAAa,YAAY,EAAE;;iBAE1C,EAAE,KAAK,SAAS,CAAC,aAAa,cAAc,GAAG;AAChE;AAEA,SAAS,kCAAkC,cAA8D;IACvG,MAAM,eAAe,MAAM,OAAO,CAAC,eAAe,YAAY,IAAI,eAAe,YAAY,CAAC,IAAI,CAAC,QAAQ,eAAe,YAAY;IACtI,MAAM,cAAc,MAAM,OAAO,CAAC,eAAe,YAAY,IAAI,eAAe,YAAY,CAAC,IAAI,CAAC,QAAQ,eAAe,YAAY;IACrI,MAAM,oBAAoB,MAAM,OAAO,CAAC,eAAe,kBAAkB,IAAI,eAAe,kBAAkB,CAAC,IAAI,CAAC,QAAQ,eAAe,kBAAkB;IAC7J,MAAM,YAAY,MAAM,OAAO,CAAC,eAAe,UAAU,IAAI,eAAe,UAAU,CAAC,IAAI,CAAC,QAAQ,eAAe,UAAU;IAE7H,OAAO,CAAC;cACI,EAAE,eAAe,WAAW,IAAI,MAAM;MAC9C,EAAE,eAAe,IAAI,IAAI,MAAM;UAC3B,EAAE,OAAO,eAAe,QAAQ,KAAK,WAAW,GAAG,eAAe,QAAQ,CAAC,IAAI,CAAC,GAAG,MAAM;cACrF,EAAE,gBAAgB,MAAM;UAC5B,EAAE,eAAe,QAAQ,IAAI,MAAM;YACjC,EAAE,eAAe,UAAU,IAAI,MAAM;iBAChC,EAAE,eAAe,oBAAoB,IAAI,MAAM;;YAEpD,EAAE,aAAa,MAAM;oBACb,EAAE,qBAAqB,MAAM;cACnC,EAAE,eAAe,MAAM;;SAE5B,EAAE,eAAe,OAAO,IAAI,OAAO;AAC5C;AAGO,eAAe;IACpB,IAAI;QACF,MAAM,UAAU,MAAM,GAAG,WAAW;QACpC,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0BAA0B;QACxC,MAAM,IAAI,MAAM,CAAC,wBAAwB,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,iBAAiB;IACvG;AACF;AAIO,eAAe,eACpB,SAAiB,EACjB,MAA+E;IAE/E,IAAI;QAEF,MAAM,QAAQ,GAAG,KAAK,CAAC;QACvB,MAAM,kBAAkB,AAAC,OAAO,SAAS,IAAI,OAAO,SAAS,CAAC,MAAM,GAAG,IACnE,OAAO,SAAS,GAChB;QACJ,MAAM,YAAY,MAAM,SAAS,CAAC;QAElC,MAAM,WAAW,MAAM,UAAU,aAAa,CAAC;YAC7C,OAAO;gBACL,MAAM,OAAO,IAAI,IAAI;gBACrB,QAAQ;oBAAE,MAAM,OAAO,KAAK;gBAAC;YAC/B;YACA,2DAA2D;YAC3D,QAAQ,OAAO,MAAM,IAAI,OAAO,MAAM,CAAC,MAAM,GAAG,IAAI,OAAO,MAAM,GAAG;QACtE;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,qCAAqC;QACnD,MAAM,IAAI,MAAM,CAAC,mCAAmC,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,iBAAiB;IAClH;AACF","debugId":null}},
    {"offset": {"line": 763, "column": 0}, "map": {"version":3,"sources":["file:///Users/itwelaibomu/Desktop/code/agents-2025-dope/apps/web/src/types/metadata.ts"],"sourcesContent":["export interface BaseMetadata {\n  createdAt?: string;\n  updatedAt?: string;\n  tags?: string[];\n  source?: string;\n}\n\nexport interface EmailTemplateMetadata extends BaseMetadata {\n  templateName: string;\n  category: 'welcome' | 'notification' | 'marketing' | 'transactional' | 'other';\n  subject?: string;\n  language?: string;\n  targetAudience?: string;\n  priority?: 'low' | 'medium' | 'high';\n}\n\nexport interface TranscriptMetadata extends BaseMetadata {\n  title?: string;\n  meetingType?: 'interview' | 'call' | 'meeting' | 'presentation' | 'other';\n  duration?: number; // in minutes\n  participants?: string[];\n  location?: string;\n  department?: string;\n  confidentialityLevel?: 'public' | 'internal' | 'confidential' | 'restricted';\n  action_items?: string[];\n  concepts_discussed?: string[];\n  date?: string;\n  key_topics?: string[];\n  summary?: string;\n}\n\nexport interface FaqMetadata extends BaseMetadata {\n  category: 'product' | 'billing' | 'technical' | 'support' | 'general' | 'other';\n  difficulty?: 'beginner' | 'intermediate' | 'advanced';\n  relatedProducts?: string[];\n  lastReviewed?: string;\n  popularity?: number; // view count or rating\n  keywords?: string[];\n}\n\nexport interface CompanyKnowledgeMetadata extends BaseMetadata {\n  department: 'engineering' | 'sales' | 'marketing' | 'hr' | 'finance' | 'legal' | 'operations' | 'other';\n  documentType?: 'policy' | 'procedure' | 'guideline' | 'training' | 'reference' | 'other';\n  accessLevel?: 'public' | 'internal' | 'restricted' | 'confidential';\n  version?: string;\n  approver?: string;\n  expirationDate?: string;\n}\n\nexport interface EmployeeDataMetadata {\n  employeeId: string;\n  name: string;\n  organization: string;\n  position: string;\n  reportsTo: string;\n  gender?: string | null;\n  assessmentDate: string;\n  all34: string[];\n  leadDomain: 'Executing' | 'Influencing' | 'Relationship Building' | 'Strategic Thinking';\n  themeDomains: {\n    Executing: string[];\n    Influencing: string[];\n    RelationshipBuilding: string[];\n    StrategyThinking: string[];\n  };\n  bestCollabWith: string;\n  communicationTips: string;\n  howToCoach: string;\n  motivators: string[];\n  demotivators: string[];\n  watchouts: string;\n  evidenceQuotes: Array<{\n    quote: string;\n    section: string;\n  }>;\n  sourceDocUrl?: string | null;\n  sourceProvenance?: string | null;\n}\n\n\nexport interface EmployeeDataInput {\n  employeeData: EmployeeDataMetadata;\n  tags?: string[] | null;\n  source?: string | null;\n}\n\nexport interface TranscriptDataInput {\n  transcriptData: TranscriptMetadata;\n  tags?: string[] | null;\n  source?: string | null;\n}\n\n\nexport type IndexMetadata = \n  | EmailTemplateMetadata \n  | TranscriptMetadata \n  | FaqMetadata \n  | CompanyKnowledgeMetadata\n  | EmployeeDataMetadata;\n\nexport interface CustomMetadataField {\n  key: string;\n  value: string;\n  type: 'text' | 'number' | 'boolean' | 'date' | 'select';\n  options?: string[]; // for select type\n}\n\nexport const INDEX_TYPES = {\n  'dope-email-templates': 'Email Templates',\n  'dope-transcript-data': 'Transcript Data', \n  'dope-faq-data': 'FAQ Data',\n  'dope-company-knowledge': 'Company Knowledge',\n  'dope-employee-data': 'Employee Data'\n} as const;\n\nexport type IndexType = keyof typeof INDEX_TYPES;\n\nexport function getMetadataFieldsForIndex(indexName: string): string[] {\n  switch (indexName) {\n    case 'dope-email-templates':\n      return ['templateName', 'category', 'subject', 'language', 'targetAudience', 'priority'];\n    case 'dope-transcript-data':\n      return ['meetingType', 'duration', 'participants', 'location', 'department', 'confidentialityLevel', 'action_items', 'concepts_discussed', 'date', 'key_topics', 'summary'];\n    case 'dope-faq-data':\n      return ['category', 'difficulty', 'relatedProducts', 'lastReviewed', 'popularity', 'keywords'];\n    case 'dope-company-knowledge':\n      return ['department', 'documentType', 'accessLevel', 'version', 'approver', 'expirationDate'];\n    case 'dope-employee-data':\n      return ['tags'];\n    default:\n      return [];\n  }\n}\n"],"names":[],"mappings":";;;;;;AA2GO,MAAM,cAAc;IACzB,wBAAwB;IACxB,wBAAwB;IACxB,iBAAiB;IACjB,0BAA0B;IAC1B,sBAAsB;AACxB;AAIO,SAAS,0BAA0B,SAAiB;IACzD,OAAQ;QACN,KAAK;YACH,OAAO;gBAAC;gBAAgB;gBAAY;gBAAW;gBAAY;gBAAkB;aAAW;QAC1F,KAAK;YACH,OAAO;gBAAC;gBAAe;gBAAY;gBAAgB;gBAAY;gBAAc;gBAAwB;gBAAgB;gBAAsB;gBAAQ;gBAAc;aAAU;QAC7K,KAAK;YACH,OAAO;gBAAC;gBAAY;gBAAc;gBAAmB;gBAAgB;gBAAc;aAAW;QAChG,KAAK;YACH,OAAO;gBAAC;gBAAc;gBAAgB;gBAAe;gBAAW;gBAAY;aAAiB;QAC/F,KAAK;YACH,OAAO;gBAAC;aAAO;QACjB;YACE,OAAO,EAAE;IACb;AACF","debugId":null}},
    {"offset": {"line": 831, "column": 0}, "map": {"version":3,"sources":["file:///Users/itwelaibomu/Desktop/code/agents-2025-dope/apps/web/src/app/api/agents/chat/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\nimport {\n  Agent,\n  AgentInputItem,\n  run,\n  tool,\n  user,\n  withTrace,\n  webSearchTool,\n  hostedMcpTool,\n  MCPServerStdio,\n} from '@openai/agents';\nimport { ConvexHttpClient } from \"convex/browser\";\nimport { api } from \"../../../../../convex/_generated/api\";\nimport Replicate from \"replicate\";\nimport { analyzeWebsiteViaFirecrawl, deepResearchAnything } from '../../../agentActions';\nimport OpenAI from \"openai\";\nimport { zodTextFormat } from \"openai/helpers/zod\";\nimport { z } from \"zod\";\nimport { listIndexesFromPinecone, createIndex, addToIndex, addEmployeeDataToIndex, addTranscriptDataToIndex, semanticSearch } from 'apps/web/src/services/pineconeService';\nimport { INDEX_TYPES } from 'apps/web/src/types/metadata';\n\n\nimport { setDefaultOpenAIKey } from '@openai/agents';\nimport { setTracingExportApiKey } from '@openai/agents';\nsetDefaultOpenAIKey(process.env.NODE_ENV === 'production' ? process.env.OPENAI_API_KEY! : process.env.NEXT_PUBLIC_OPENAI_API_KEY!);\nsetTracingExportApiKey(process.env.NODE_ENV === 'production' ? process.env.OPENAI_API_KEY! : process.env.NEXT_PUBLIC_OPENAI_API_KEY!);\n\nconst replicate = new Replicate({\n  auth: process.env.NODE_ENV === 'production' ? process.env.REPLICATE_API_KEY! : process.env.NEXT_PUBLIC_REPLICATE_API_KEY!\n});\n\nconst openai = new OpenAI({\n  apiKey: process.env.NODE_ENV === 'production' ? process.env.OPENAI_API_KEY! : process.env.NEXT_PUBLIC_OPENAI_API_KEY!,\n});\n\n// Ensure Node.js runtime for stdio processes\nexport const runtime = 'nodejs';\n\n// MCP: Sequential Thinking server via stdio\nconst sequentialThinkingServer = new MCPServerStdio({\n  name: 'sequential_thinking',\n  fullCommand: 'npx -y @modelcontextprotocol/server-sequential-thinking',\n});\n\n/* ------------------------------------------------------------------------------------------------\n\nREVIEW: Types\n\n-------------------------------------------------------------------------------------------------- */ \n\nconst emailSchema = z.object({\n  subject: z.string(),\n  body: z.string(),\n  businessName: z.string(),\n  templateUsed: z.string(),\n  websiteName: z.string(),\n  reasonForUsingTemplate: z.string().describe('The reason for using the template. No longer than 100 words.'),\n});\n\n\n/* ------------------------------------------------------------------------------------------------\n\nREVIEW: Constants\n\n-------------------------------------------------------------------------------------------------- */ \n\nconst emailTemplates = [\n  {\n    name: 'Last 10 Jobs → Neighbors',\n    description: 'Neighborhood Reactivation campaign targeting neighbors of recent job sites',\n    template: `Subject options:\n    - Your last 10 jobs = fast new leads\n    - Neighbors are 10x more likely to hire you\n    - Turn finished work into more jobs this week\n\n      Body:\n      Hey [First Name/Company Name],\n      Send me your last 10 jobs and I'll launch a Neighborhood Reactivation: we hit the homes around those addresses with a clean postcard design. Neighbors who saw your crew are 10x more likely to call. Approve the proof and we'll have mail out in <5 days.\n      Want me to pull the list or do you have it handy?\n      – Team DOPE`,\n  },\n\n  {\n    name: 'No Minimum. Upload & Go.',\n    description: 'Flexible campaign with no minimums for quick job list targeting',\n    template: `Subject options:\n    - No minimum—upload and mail in <5 days\n    - Hit any job list fast (10, 20, 50+)\n    - Simple way to fill your schedule\n\n    Body:\n    Hey [First Name/Company Name],\n    Upload your last 10 (or 20, or 50) jobs—no minimums. We'll target the neighbors with postcards and get them out in under 5 days. Warm area, quick turnaround, predictable results.\n    Reply \"GO\" and I'll set it up now.\n    – Team DOPE`,\n  },\n  \n  {\n    name: 'Mail Out in <5 Days',\n    description: 'Quick turnaround campaign focusing on speed and neighboring areas',\n    template: `Subject options:\n    - Quick win: more jobs this week\n    - Postcards in mailboxes in under 5 days\n    - Your next jobs are right next door\n\n    Body:\n    Hey [First Name/Company Name],\n    You've already done the hard part. Send your recent job addresses, approve a postcard, and we'll mail the neighbors in <5 days. It's fast, affordable, and focuses on the exact neighborhoods you want.\n    Ready to launch this week?\n    – Team DOPE`,\n  },\n  \n];\nconst whoIsDopeMarketing = `\n    Who is DOPE Marketing?\n\n    Dope Marketing is a data-driven marketing platform and direct print and mail company specializing in making marketing predictable, data-driven, and friction-free for businesses aiming to grow. Founded by CEO Dave Carroll, the company emerged to simplify direct mail, growing from a software solution to a 100+ person operation with its own 40,000 sq. ft. print facility and a full SaaS platform.\n\n    Their core offering is automated direct mail, which integrates with CRMs for hyperlocal targeting and offers services with no minimum order. Dope Marketing caters primarily to local and home service brands such as roofers, lawn care, pest control, remodelers, HVAC, plumbing, and electrical, but also serves various other industries including real estate, insurance, and restaurants.\n\n    Key features and services include:\n\n    Direct Mail Automation: Sending postcards, handwritten notes, and gifts automatically based on triggers from a business's CRM.\n\n    Neighborhood Blitz: A tool for highly targeted mailings to specific geographic areas or demographics, leveraging CRM data.\n\n    CRM Integrations: Seamlessly connecting with popular CRMs like GoHighLevel, Zapier, Salesforce, and HubSpot to automate marketing efforts.\n\n    In-house Design and Production: They own both the technology and the print shop, ensuring control over every step from design (with a dedicated team and templates) to printing and shipping.\n\n    Print Products: Beyond automated mail, they offer yard signs, door hangers, and business cards.\n\n    No Minimum Orders: Allowing businesses of all sizes to utilize their services.\n\n    Tracking: Providing visibility into campaign performance.\n\n    Dope Marketing differentiates itself through its comprehensive, data-driven approach, owning the entire direct mail process, and its strong focus on helping local and home service businesses achieve measurable ROI. The \"DOPE\" in their name stands for \"Data On Previous Engagement\".\n`\nconst dopeVoice = `\n\nDOPE VOICE — Compact Guide (use for every email)\n\nYou are Dope Marketing’s senior conversion copywriter. Adopt one consistent voice for every outbound email: direct, pragmatic, and action‑first. About 70% matter‑of‑fact, 30% purposeful founder energy. Short sentences, active verbs, concrete offers, and one clear reply‑based CTA are non‑negotiable.\n\nCore priority: personalization that converts\n\nWhen the user provides client info, weave that information into the subject or preview and or body so the message feels specific and relevant.\nUse client info to make one concrete, believable claim (e.g., “Given your Little Canada house‑wash offering, a 7‑day pilot in one neighborhood usually surfaces booked jobs”) — do NOT invent data or claim site scans unless the user explicitly provided those facts.\nUse no more than one or two/ specific signals to avoid overload; keep personalization tight and evidence‑based.\nPersonalization should always support an immediate conversion action (pilot, audit, inspection).\nVoice & tone\n\nDirect and assertive; outcome-driven (booked jobs, CPL, lift).\nConfident and efficient — professional but energetic; avoid jokes, slang, or personal anecdotes.\nSubtle urgency/seasonality allowed when relevant (e.g., “fall leaf load,” “pre‑winter”).\nStructure & format (required)\n\nOutput exactly these labeled fields:\nSubject: [≤ 7 words, benefit-driven, may include one token like City or Service]\nPreview: [1-line clarifier, ~8–12 words]\nBody: [80–140 words — single paragraph or 2 short paragraphs; optional 1–3 bullets max]\nSignoff: —Dope Marketing\nExactly one CTA and it must be reply-text (e.g., Reply “YES”, Reply “Set it up”, Reply “Go”). No multiple CTAs or link-first CTAs in initial outreach.\nContent rules\n\nOpen with a 1-line hook that uses the provided client signal (if any) and frames a specific problem or seasonal trigger (e.g., “For Little Canada homes, fall gutters create winter risk”). If no signal provided, use a neutral industry hook.\nFollow with a short insight/benefit (1–2 sentences) using active verbs: run, test, pilot, measure, automate, scale.\nOffer must be one sentence and scoped: what Dope will do, what client does, and what deliverable/metric is delivered (e.g., “7‑day pilot — we run ads, deliver booked list + HubSpot metrics”).\nInclude one credibility token when appropriate (HubSpot, CPL, booked job, before/after photos, years in market).\nPersonalization limit: at most one specific signal beyond Company to keep messages sharp and believable.\nLanguage & phrasing\n\nShort, punchy sentences. Active voice.\nUse numeric quantifiers and concrete timeframes (7‑day pilot, 20‑minute audit, 30‑minute inspection).\nFavor reply CTAs and low‑friction asks.\nAvoid corporate buzzwords and emotional fluff.\nInclude one small proof point in follow-ups if available (metric + similar client).\nBullets\n\nUse bullets only for clarity (2–4 items maximum). Each ≤ 10 words.\nLength & quality checks\n\nBody length: 80–140 words. Truncate if longer.\nExactly one reply-based CTA.\nNo jokes, slang, or founder anecdotes.\nUse at least one credibility token when relevant.\nSubject ≤ 7 words and benefit-focused.\nTokens/phrases to use\n\npilot, run, test, measure, ship, automate, track, CPL, booked job(s), HubSpot, photo documentation, neighborhood push, booking flow, steam ice-dam removal, 7‑day pilot, 20‑minute audit.\nProhibitions\n\nDo not invent facts or attribute actions you haven’t been given. Only use client details the user supplies.\nNo more than one casual/founder‑energy phrase per email and only if it aids clarity.\nClarifying rule\n\nIf required input is missing (Company, Service, or CTA), ask exactly one clarifying question instead of guessing.\n\n`\nconst whenToUseTools = `\n\n  If you are given a task with more than 1 step, you must use sequential thinking to plan out the task first.\n  Then, you must use the appropriate tool to complete each step.\n  Then, you must return the final result to the user.\n\n  If you are given a task or find you need up to date information, you can use your best judgement on if the web search tool would be useful.\n\n  If a user says: I want to use your web search tool to... then you should use the web search tool.\n  I want to use your thinking mode tool to... then you should use the sequential thinking tool.\n\n`\nconst howToGenerateAProsal = `\n\n  HOW TO GENERATE A PROPOSAL:\n\n  First, if you are given a client list/ list of client information, attempt to identify the website of the business based on the emails in the data.\n  Then, give the website name, business name, and if the user explicitly requested a template, give the template name to the email_creation_by_website_and_template tool.\n  Then use the list_how_to_generate_a_proposal tool to understand what I am looking for in the response, what to avoid, and how to format the email.\n  Last, give back afew things to the user. Provide the Subject, Body (fully filled in, placeholders filled in, ready to send with context scraped from the website weaved in as well), Business Name (preferably from the scraped website data), the template used, and the reasoning for using the template. This email needs to literally be ready to send, placeholders filled in, and fully ready to go.\n\n  What to avoid\n  Long paragraphs. Jargon. Multiple CTAs. Vague promises. Overuse of emojis.\n  Do not use and I mean NEVER use \"---\" in the email to separate sections, trains of thought, etc. This is a tell tale sign of a bot. Do not use \"---\" in the email.\n  The Body you generate needs to be fully filled in, placeholders filled in, ready to send with context scraped from the website weaved in as well. Like I need to be able to copy it a paste it directly into an email client and have it be ready to send.\n  Format it in a way where it is the easiest to do that\n\n`\n\n// Simple content extraction for saved messages\nconst extractContent = (content: any): string => {\n  if (typeof content === 'string') {\n    return content;\n  } else if (content && typeof content === 'object') {\n    if (content.text) return content.text;\n    if (content.content) return content.content;\n    if (Array.isArray(content)) {\n      return content.map(c => \n        typeof c === 'string' ? c : (c.text || c.content || JSON.stringify(c))\n      ).join(' ');\n    }\n    return JSON.stringify(content);\n  }\n  return String(content || '');\n};\n\nconst generateConversationTitle = async (firstMessage: string) => {\n  try {\n    const systemPrompt = `\n    You are a helpful assistant that generates short, descriptive titles for conversations.\n    Create a concise title (max 50 characters) that captures the main topic or intent of the conversation.\n    Be specific and avoid generic titles like \"Chat\" or \"Conversation\".\n    `;\n\n    const userPrompt = `\n    Generate a title for this conversation that starts with: \"${firstMessage}\"\n    `;\n    \n    const response = await openai.chat.completions.create({\n      model: \"gpt-5-nano\",\n      messages: [\n        { role: \"system\", content: systemPrompt },\n        { role: \"user\", content: userPrompt },\n      ],\n      max_completion_tokens: 20,\n      temperature: 0.7,\n    });\n\n    return response.choices[0]?.message?.content?.trim() || \"New Chat\";\n  } catch (error) {\n    console.error('Error generating conversation title:', error);\n    // Return a fallback title based on the first message\n    const truncatedMessage = firstMessage.substring(0, 30);\n    return truncatedMessage.length < firstMessage.length \n      ? `${truncatedMessage}...` \n      : truncatedMessage;\n  }\n}\n\n/* ------------------------------------------------------------------------------------------------\n\nREVIEW TOOLS FOR HERMES\n\n-------------------------------------------------------------------------------------------------- */ \n\nconst listTemplatesTool = tool({\n  name: 'list_templates',\n  description: 'List all the templates available',\n  parameters: z.object({}),\n  execute: async (input) => {\n    return emailTemplates;\n  },\n});\nconst emailCreationByWebsiteAndTemplateTool = tool({\n  name: 'email_creation_by_website_and_template',\n  description: 'Create an email based on a website and template',\n  parameters: z.object({\n    websiteName: z.string().describe('The website to use for scraping'),\n    businessName: z.string().describe('The business name to use'),\n    userRequestedTemplateName: z.string().nullable().describe('The template to use if the user explicitly requested it'),\n  }),\n  execute: async (input) => {\n\n    const { websiteName, businessName, userRequestedTemplateName } = input;  \n\n    const allScrapedWebsiteInformation = await analyzeWebsiteViaFirecrawl(websiteName, 'content');\n\n    // Prefer structured extraction result from Firecrawl; fallback to OpenAI summarizer if unavailable\n    const tailoredSummaryOfWebsiteScrape = allScrapedWebsiteInformation?.structured\n    \n    const systemPrompt = `Your goal is to write a higly personlized outreach email FROM DOPE TO a potential client using all the information provided to you.\n\n    Here is some information about DOPE Marketing:\n    ${whoIsDopeMarketing}\n\n    Here is the voice of DOPE Marketing:\n    ${dopeVoice}\n\n\n  EMAIL TEMPLATES TO USE (from DOPE's perspective), you must use one of these templates:\n  ${emailTemplates.map(template => `Name: ${template.name}\\nDescription: ${template.description}\\nTemplate: ${template.template}`).join('\\n\\n')}\n\n\n    Generate a complete, personalized marketing email FROM DOPE TO ${businessName}.`;\n\n    const userPrompt = `\n\n    TARGET BUSINESS NAME:\n    ${businessName}\n\n    TARGET BUSINESS WEBSITE INFORMATION:\n    ${tailoredSummaryOfWebsiteScrape}\n\n    ${userRequestedTemplateName ? `\n      The User explicitly requested the following template: ${emailTemplates.find(template => template.name === userRequestedTemplateName)?.name}` \n    : ``}\n\n    Generate a complete, personalized marketing email FROM DOPE TO ${businessName}.`;\n\n    const response = await openai.responses.parse({\n      model: \"gpt-5-mini\",\n      input: [\n        { role: \"system\", content: systemPrompt },\n        {\n          role: \"user\",\n          content: userPrompt,\n        },\n      ],\n      text: {\n        format: zodTextFormat(emailSchema, \"email\"),\n      },\n    });\n    \n    const emailResponseData = response.output_parsed;\n    \n    return {\n        subject: emailResponseData?.subject,\n        body: emailResponseData?.body,\n        businessName: emailResponseData?.businessName,\n        templateUsed: emailResponseData?.templateUsed,\n        websiteName: emailResponseData?.websiteName,\n        reasonForUsingTemplate: emailResponseData?.reasonForUsingTemplate,\n    };\n\n  },\n});\nconst listHowToGenerateAProsal = tool({\n  name: 'list_how_to_generate_a_proposal',\n  description: 'List the steps to generate a proposal',\n  parameters: z.object({}),\n  execute: async (input) => {\n    return howToGenerateAProsal;\n  },\n});\n\n/* ------------------------------------------------------------------------------------------------\n\nREVIEW TOOLS FOR STEVE\n\n-------------------------------------------------------------------------------------------------- */ \n\nconst facilitateStandupTool = tool({\n  name: 'facilitate_standup',\n  description: 'Help facilitate standup meetings and team communication',\n  parameters: z.object({\n    teamSize: z.number().describe('Number of team members'),\n    agenda: z.string().nullable().optional().describe('Specific agenda items'),\n  }),\n  execute: async (input) => {\n    const { teamSize, agenda } = input;\n    \n    const standupStructure = [\n      '# Standup Meeting Structure\\n\\n',\n      '## Standard Format\\n',\n      '- What did you accomplish yesterday?\\n',\n      '- What will you work on today?\\n',\n      '- Are there any blockers or challenges?\\n\\n',\n      `## Team Size: ${teamSize} members\\n`,\n      `**Recommended duration:** ${Math.ceil(teamSize * 2)} minutes\\n\\n`,\n      agenda ? `## Additional Agenda Items\\n${agenda}\\n\\n` : '',\n      '## Best Practices\\n',\n      '- Keep updates concise and focused\\n',\n      '- Address blockers immediately after standup\\n',\n      '- Encourage team collaboration and support'\n    ];\n    \n    return standupStructure.join('');\n  },\n});\n\n/* ------------------------------------------------------------------------------------------------\n\nREVIEW TOOLS FOR ATLAS\n\n-------------------------------------------------------------------------------------------------- */ \n\nconst analyzeWebsiteTool = tool({\n  name: 'analyze_website',\n  description: `Conduct website analysis for business intelligence and competitive insights.\n  \n  If the analysis type is \"gather-style-of-speaking\", you need to take the results and come up with a master plan for the style of speaking of the website.\n  Think lexicon, tone, stlye, go in depth.\n  This needs to be somehting that is directly useful for an Ai to use to speak like how you notice on the website.\n\n  `,\n  parameters: z.object({\n    websiteUrl: z.string().describe('URL of the website to analyze'),\n    analysisType: z.string().describe('Type of analysis: content, gather-style-of-speaking'),\n  }),\n  execute: async (input) => {\n    const { websiteUrl, analysisType } = input;\n\n    let allScrapedWebsiteInformation = null;\n    let tailoredSummaryOfWebsiteScrape = null;\n    let styleOfSpeaking = null;\n\n    if (analysisType === 'gather-style-of-speaking') {\n\n      /* \n      ------------------------------------------------------------\n      We want to gather the style of speaking of the website.\n      Because of this, we need to gather more information from the website.\n      Thus, the limit is set to 50.\n      ------------------------------------------------------------\n      */\n      styleOfSpeaking = await analyzeWebsiteViaFirecrawl(websiteUrl, analysisType as 'content' | 'gather-style-of-speaking');\n\n      return {\n        websiteUrl: websiteUrl,\n        analysisType: analysisType,\n        source: styleOfSpeaking?.source,\n        styleOfSpeaking: styleOfSpeaking?.structured,\n      };\n\n    } else {\n\n      allScrapedWebsiteInformation = await analyzeWebsiteViaFirecrawl(websiteUrl, analysisType as 'content' | 'gather-style-of-speaking');\n      tailoredSummaryOfWebsiteScrape = allScrapedWebsiteInformation?.structured\n\n      return {\n        websiteUrl: websiteUrl,\n        analysisType: analysisType,\n        tailoredSummaryOfWebsiteScrape: tailoredSummaryOfWebsiteScrape,\n      };\n      \n    }\n\n  },\n});\n\nconst deepResearchTool = tool({\n  name: 'deep_research',\n  description: 'Research ANYTHING - companies, people, topics, industries, trends, technologies, etc. Completely flexible research tool for any query.',\n  parameters: z.object({\n    researchQuery: z.string().describe('What you want to research. Examples: \"Tesla competitors\", \"AI trends 2024\", \"How does Netflix content strategy work\", \"Sustainable packaging solutions\", \"Remote work productivity tools\", etc.'),\n    websiteUrl: z.string().optional().nullable().describe('Optional: Include a specific website to focus research on, or null to research the topic generally'),\n  }),\n  execute: async (input) => {\n    const { researchQuery, websiteUrl } = input;\n    return await deepResearchAnything(researchQuery, websiteUrl || undefined);\n  },\n});\n\n\n/* ------------------------------------------------------------------------------------------------\n\nREVIEW TOOLS FOR JUNO\n\n-------------------------------------------------------------------------------------------------- */ \n\nconst queryDataTool = tool({\n  name: 'query_data',\n  description: 'Connect to data analytics tools and provide insights',\n  parameters: z.object({\n    dataSource: z.string().describe('The data source or database to query'),\n    queryType: z.string().describe('Type of analysis: performance, trends, comparison'),\n  }),\n  execute: async (input) => {\n    const { dataSource, queryType } = input;\n    \n    // Mock data analysis (would connect to Metabase in production)\n    const dataInsights = [\n      `# Data Analytics Report\\n\\n`,\n      `**Data Source:** ${dataSource}\\n`,\n      `**Query Type:** ${queryType}\\n\\n`,\n      `## Key Metrics\\n`,\n      `- Performance indicators show positive trends\\n`,\n      `- Data quality is within acceptable parameters\\n`,\n      `- Recent patterns indicate growth opportunities\\n\\n`,\n      `## Insights\\n`,\n      `- Recommendation: Focus on high-performing segments\\n`,\n      `- Consider expanding successful strategies\\n`,\n      `- Monitor key performance indicators regularly\\n\\n`,\n      `## Next Steps\\n`,\n      `- Set up automated reporting for continuous monitoring\\n`,\n      `- Implement data-driven decision making processes\\n`,\n      `- Schedule regular analysis reviews`\n    ];\n    \n    return dataInsights.join('');\n  },\n});\n\n/* ------------------------------------------------------------------------------------------------\n\nREVIEW TOOLS FOR DOPE ADMIN\n\n-------------------------------------------------------------------------------------------------- */ \n\n// pinecone tools\nconst pineconeListIndexesTool = tool({\n  name: 'pinecone_list_indexes',\n  description: 'List all the indexes in Pinecone',\n  parameters: z.object({}),\n  execute: async (input) => {\n    return await listIndexesFromPinecone();\n  },\n});\n\nconst pineconeCreateIndexTool = tool({\n  name: 'pinecone_create_index',\n  description: 'Create a new Pinecone index',\n  parameters: z.object({\n    indexName: z.string().describe('The name of the Pinecone index to create'),\n  }),\n  execute: async (input) => {\n    const { indexName } = input;\n    return await createIndex(indexName);\n  },\n});\nconst pineconeAddEmployeeDataToIndexTool = tool({\n  name: 'pinecone_add_employee_data_to_index',\n  description: 'Add employee data to a Pinecone index.',\n  parameters: z.object({\n    data: z.object({\n      employeeData: z.object({\n        employeeId: z.string().describe('Employee ID'),\n        name: z.string().describe('Full name'),\n        organization: z.string().describe('Organization'),\n        position: z.string().describe('Position'),\n        reportsTo: z.string().describe('Reports to'),\n        gender: z.string().optional().nullable().describe('Gender'),\n        assessmentDate: z.string().describe('Assessment date'),\n        all34: z.array(z.string()).describe('All 34 strengths'),\n        leadDomain: z.enum(['Executing', 'Influencing', 'Relationship Building', 'Strategic Thinking']).describe('Lead domain'),\n        themeDomains: z.object({\n          Executing: z.array(z.string()),\n          Influencing: z.array(z.string()),\n          RelationshipBuilding: z.array(z.string()),\n          StrategyThinking: z.array(z.string()),\n        }).describe('Theme domains'),\n        bestCollabWith: z.string().describe('Best collaboration description'),\n        communicationTips: z.string().describe('Communication tips'),\n        howToCoach: z.string().describe('How to coach'),\n        motivators: z.array(z.string()).describe('Motivators'),\n        demotivators: z.array(z.string()).describe('Demotivators'),\n        watchouts: z.string().describe('Watchouts'),\n        evidenceQuotes: z.array(z.object({\n          quote: z.string(),\n          section: z.string(),\n        })).describe('Evidence quotes'),\n        sourceDocUrl: z.string().optional().nullable().describe('Source document URL'),\n        sourceProvenance: z.string().optional().nullable().describe('Source provenance'),\n      }).describe('Employee data'),\n      tags: z.array(z.string()).optional().nullable().describe('Tags for categorization'),\n      source: z.string().optional().nullable().describe('Source information'),\n    }).describe('The employee data to add to the Pinecone index'),\n  }),\n  execute: async (input) => {\n    const { data } = input;\n    return await addEmployeeDataToIndex('dope-employee-data', data);\n  },\n});\nconst pineconeAddTranscriptDataToIndexTool = tool({\n  name: 'pinecone_add_transcript_data_to_index',\n  description: 'Add transcript data to a Pinecone index',\n  parameters: z.object({\n    data: z.object({\n      transcriptData: z.object({\n        title: z.string().describe('The title of the transcript'),\n        meetingType: z.enum(['interview', 'call', 'meeting', 'presentation', 'other']).optional().nullable(),\n        duration: z.number().optional().nullable().describe('Duration in minutes'),\n        participants: z.array(z.string()).optional().nullable(),\n        location: z.string().optional().nullable(),\n        department: z.string().optional().nullable(),\n        confidentialityLevel: z.enum(['public', 'internal', 'confidential', 'restricted']).optional().nullable(),\n        action_items: z.array(z.string()).optional().nullable(),\n        concepts_discussed: z.array(z.string()).optional().nullable(),\n        date: z.string().optional().nullable(),\n        key_topics: z.array(z.string()).optional().nullable(),\n        summary: z.string().optional().nullable(),\n      }).describe('Transcript metadata'),\n      tags: z.array(z.string()).optional().nullable(),\n      source: z.string().optional().nullable(),\n    }).describe('The transcript data to add to the Pinecone index'),\n  }),\n  execute: async (input) => {\n    const { data } = input;\n    const td = data.transcriptData || {} as any;\n    const cleaned = {\n      transcriptData: {\n        title: td.title ?? undefined,\n        meetingType: td.meetingType ?? undefined,\n        duration: td.duration ?? undefined,\n        participants: Array.isArray(td.participants) ? td.participants : (td.participants ?? undefined),\n        location: td.location ?? undefined,\n        department: td.department ?? undefined,\n        confidentialityLevel: td.confidentialityLevel ?? undefined,\n        action_items: Array.isArray(td.action_items) ? td.action_items : (td.action_items ?? undefined),\n        concepts_discussed: Array.isArray(td.concepts_discussed) ? td.concepts_discussed : (td.concepts_discussed ?? undefined),\n        date: td.date ?? undefined,\n        key_topics: Array.isArray(td.key_topics) ? td.key_topics : (td.key_topics ?? undefined),\n        summary: td.summary ?? undefined,\n      },\n      tags: Array.isArray(data.tags) ? data.tags : (data.tags ?? undefined),\n      source: data.source ?? undefined,\n    } as any;\n\n    return await addTranscriptDataToIndex('dope-transcript-data', cleaned);\n  },\n});\n\n// pinecone add to index\nconst pineconeAddToIndexTool = tool({\n  name: 'pinecone_add_to_index',\n  description: 'Add data to a Pinecone index',\n  parameters: z.object({\n    indexName: z.string().describe('The name of the Pinecone index to add data to. The current indexes are: ' + Object.values(INDEX_TYPES).join(', ')),\n    data: z.object({\n      title: z.string().describe('The title of the document'),\n      content: z.string().describe('The content to add to the index'),\n      // Restrict metadata to JSON-safe primitives and arrays so the schema has explicit types\n      metadata: z\n        .record(\n          z.string(),\n          z.union([\n            z.string(),\n            z.number(),\n            z.boolean(),\n            z.array(z.string()),\n            z.array(z.number()),\n            z.array(z.boolean()),\n          ])\n        )\n        .optional()\n        .nullable()\n        .describe('Optional metadata for the document (string/number/boolean or arrays of these values only).'),\n    }).describe('The data to add to the Pinecone index'),\n  }),\n  execute: async (input) => {\n    const { indexName, data } = input;\n    return await addToIndex(indexName, {\n      title: data.title,\n      content: data.content,\n      metadata: data.metadata || undefined,\n    });\n  },\n});\n\n// pinecone semantic search tool\nconst pineconeSemanticSearchTool = tool({\n  name: 'pinecone_semantic_search',\n  description: 'Perform semantic search on a Pinecone index using query text (requires integrated embeddings).',\n  parameters: z.object({\n    indexName: z.string().describe('Index name to search in, it is your job to pick the right appropriate index to search in. The current indexes are: dope-email-templates (Email Templates), dope-transcript-data (Transcript Data), dope-faq-data (FAQ Data), dope-company-knowledge (Company Knowledge), dope-employee-data (Employee Data)'),\n    query: z.string().describe('The query text to search for'),\n    topK: z.number().int().positive().max(1000).optional().nullable().describe('Number of similar records to return (default 5)'),\n    fields: z.array(z.string()).optional().nullable().describe('Optional list of fields to include in results'),\n  }),\n  execute: async (input) => {\n    const { indexName, query, topK, fields } = input;\n    const response = await semanticSearch(indexName, {\n      query,\n      topK: topK ?? undefined,\n      namespace: '__default__',\n      fields: fields ?? undefined,\n    });\n    return response;\n  },\n});\n\n// dope-company-knowledge semantic search tool\nconst pineconeCompanyKnowledgeSemanticSearchTool = tool({\n  name: 'pinecone_company_knowledge_semantic_search',\n  description: 'Perform semantic search on the dope-company-knowledge index',\n  parameters: z.object({\n    query: z.string().describe('The query text to search for'),\n  }),\n  execute: async (input) => {\n    const { query } = input;\n    return await semanticSearch('dope-company-knowledge', { query, topK: 5, namespace: '__default__', fields: undefined });\n  },\n});\n// dope-employee-data semantic search tool\nconst pineconeEmployeeDataSemanticSearchTool = tool({\n  name: 'pinecone_employee_data_semantic_search',\n  description: 'Perform semantic search on the dope-employee-data index',\n  parameters: z.object({\n    query: z.string().describe('The query text to search for'),\n  }),\n  execute: async (input) => {\n    const { query } = input;\n    return await semanticSearch('dope-employee-data', { query, topK: 5, namespace: '__default__', fields: undefined });\n  },\n});\n// dope-transcript-data semantic search tool\nconst pineconeTranscriptDataSemanticSearchTool = tool({\n  name: 'pinecone_transcript_data_semantic_search',\n  description: 'Perform semantic search on the dope-transcript-data index',\n  parameters: z.object({\n    query: z.string().describe('The query text to search for'),\n  }),\n  execute: async (input) => {\n    const { query } = input;\n    return await semanticSearch('dope-transcript-data', { query, topK: 5, namespace: '__default__', fields: undefined });\n  },\n});\n// dope-email-templates semantic search tool\nconst pineconeEmailTemplatesSemanticSearchTool = tool({\n  name: 'pinecone_email_templates_semantic_search',\n  description: 'Perform semantic search on the dope-email-templates index',\n  parameters: z.object({\n    query: z.string().describe('The query text to search for'),\n  }),\n  execute: async (input) => {\n    const { query } = input;\n    return await semanticSearch('dope-email-templates', { query, topK: 5, namespace: '__default__', fields: undefined });\n  },\n});\n// dope-faq-data semantic search tool\nconst pineconeFaqDataSemanticSearchTool = tool({\n  name: 'pinecone_faq_data_semantic_search',\n  description: 'Perform semantic search on the dope-faq-data index',\n  parameters: z.object({\n    query: z.string().describe('The query text to search for'),\n  }),\n  execute: async (input) => {\n    const { query } = input;\n    return await semanticSearch('dope-faq-data', { query, topK: 5, namespace: '__default__', fields: undefined });\n  },\n});\n\n\n/* ------------------------------------------------------------------------------------------------\n\nREVIEW AGENTS\n\n-------------------------------------------------------------------------------------------------- */ \n\nconst atlasAgent = new Agent({\n  name: 'Atlas',\n  instructions: `You are Atlas, a Business Intelligence Agent. You have the ability to conduct website analysis.\n\n  Your key capabilities include:\n  - Scanning websites to assess and give the user a deeper understanding of the business.\n  - Generating targeted questions based on analyzed data for deeper understanding during interviews.\n  - It is nessesary for you to return the information given throguh analysis tools. Don't leave anything out.\n  - Being helpful overall and being a good agent.\n\n  What I don't want you to do:\n  - Give quick improvement ideas.\n  - Conversion & UX suggestions.\n  \n  Just give the user a good understanding of the business.\n  \n  Whatever the user asks, use your tools to your advantage. For other specialized tasks, hand off to the appropriate agent.`,\n  handoffDescription: 'Atlas - Business Intelligence Agent - Conducts website analysis.',\n  tools: [analyzeWebsiteTool, deepResearchTool],\n  mcpServers: [sequentialThinkingServer],\n  model: \"gpt-5-mini\",\n  modelSettings: {\n    parallelToolCalls: true,\n  }\n});\n// Agents as tools\nconst atlasTool = atlasAgent.asTool({\n  toolName: 'atlas tool',\n  toolDescription: 'Analyze a website for business intelligence.',\n})\n\nconst hermesAgent = new Agent({\n  name: 'Hermes',\n  instructions: `You are Hermes, a Proposal Generator agent for DOPE Marketing. You utilize templates and company information to generate tailored proposals that we can use to sell our services to our clients. \n\n    ${whoIsDopeMarketing}\n\n    ${dopeVoice}\n    \n    Your key capabilities include:\n    - Creating proposals based on client needs and company standards\n    - Integrating insights from previous proposals to enhance relevance and effectiveness\n    - Streamlining the proposal creation process for faster turnaround times\n    - Supporting the sales team with high-quality, persuasive proposals tailored to each client's unique requirements\n    - Being helpful overall and being a good agent.\n    \n    - NOTE: if the user explicitly requests a template, use the list_templates tool to find the exact template name and then use the userRequestedTemplateName parameter to pass the template name to the email_creation_by_website_and_template tool.\n    - NOTE: if the user requests about information on DOPE Marketing, use the pinecone_semantic_search tool to search the DOPE Knowledge Base.\n\n    ${howToGenerateAProsal}.\n\n    When users need proposal generation, use sequential thinking first to plan out the task and then follow the steps to generate a proposal. For other specialized tasks, hand off to the appropriate agent.\n\n    Here are the templates we have available just for reference:\n    ${emailTemplates.map(template => `- ${template.name}: ${template.description}`).join('\\n')}\n\n  `,\n  handoffDescription: 'Hermes - Proposal Generator - Creates tailored proposals based on client needs and company standards.',\n  tools: [listTemplatesTool, emailCreationByWebsiteAndTemplateTool, listHowToGenerateAProsal, pineconeCompanyKnowledgeSemanticSearchTool, pineconeEmailTemplatesSemanticSearchTool, pineconeTranscriptDataSemanticSearchTool, pineconeFaqDataSemanticSearchTool],\n  mcpServers: [sequentialThinkingServer],\n  model: \"gpt-5-mini\",\n  modelSettings: {\n    parallelToolCalls: true,\n  }\n});\n\nconst steveAgent = new Agent({\n  name: 'Steve',\n  instructions: `You are Steve, a Leadership Agent. You leverage CliftonStrengths and employee profiles to enhance team collaboration and development.\n\n  Your key capabilities include:\n  - Facilitating standup meetings for improved communication\n  - Supporting training and onboarding processes to integrate new employees effectively\n  - Assisting in creating performance improvement plans tailored to individual strengths\n  - Developing strategic rollout documents to guide organizational initiatives\n  \n  When users need leadership support, team development, or meeting facilitation, use your tools to provide structured guidance. For other specialized tasks, hand off to the appropriate agent.\n  \n  SOME TIPS:\n    - Be genuinely helpful and interested\n    - Ask follow-up questions to keep chatting\n    - Always respond conversationally, never like you're searching\n    - Ask engaging follow-up questions\n  `,\n  handoffDescription: 'Steve - Leadership Agent - Enhances team collaboration and development using CliftonStrengths and employee profiles.',\n  tools: [atlasTool, facilitateStandupTool, pineconeAddTranscriptDataToIndexTool, pineconeCompanyKnowledgeSemanticSearchTool, pineconeEmployeeDataSemanticSearchTool, pineconeTranscriptDataSemanticSearchTool, webSearchTool()],\n  mcpServers: [sequentialThinkingServer],\n  model: \"gpt-5-mini\",\n  modelSettings: {\n    parallelToolCalls: true,\n  }\n});\n\nconst junoAgent = new Agent({\n  name: 'Juno',\n  instructions: `You are Juno, a Data Integration Agent. You connect to data analytics tools like Metabase to provide comprehensive data analytics capabilities.\n\n  Your key capabilities include:\n  - Centralizing data access to eliminate the need for multiple tools, improving effectiveness\n  - Providing insights derived from data analytics to support decision-making processes\n  - Currently undergoing testing to ensure seamless connectivity and functionality\n  \n  When users need data analytics, insights, or database queries, use your tools to provide comprehensive analysis. For other specialized tasks, hand off to the appropriate agent.`,\n  handoffDescription: 'Juno - Data Integration Agent - Connects to Metabase and other tools for comprehensive data analytics.',\n  tools: [queryDataTool, webSearchTool()],\n  mcpServers: [sequentialThinkingServer],\n  model: \"gpt-5-mini\",\n  modelSettings: {\n    parallelToolCalls: true,\n  }\n});\n\nconst dopeAdminAgent = new Agent({\n  name: 'Dope Admin',\n  instructions: `You are Dope Admin, a Dope Marketing Admin Agent. You are going to help the engineeer complete any tasks and just be helpful overall.\n  `,\n  handoffDescription: 'Dope Admin - Dope Marketing Admin Agent - Helps the engineer complete any tasks and is helpful overall.',\n  tools: [webSearchTool(), pineconeListIndexesTool, pineconeCreateIndexTool, pineconeAddToIndexTool, pineconeAddEmployeeDataToIndexTool, pineconeAddTranscriptDataToIndexTool, pineconeSemanticSearchTool],\n  mcpServers: [sequentialThinkingServer],\n  model: \"gpt-5-mini\",\n  modelSettings: {\n    parallelToolCalls: true,\n  }\n});\n\n// Set up handoffs between agents\nhermesAgent.handoffs = [steveAgent, atlasAgent, junoAgent];\nsteveAgent.handoffs = [hermesAgent, atlasAgent, junoAgent];\natlasAgent.handoffs = [hermesAgent, steveAgent, junoAgent];\njunoAgent.handoffs = [hermesAgent, steveAgent, atlasAgent];\n\n\n// Request/Response schemas\nconst ChatRequestSchema = z.object({\n  message: z.string(),\n  threadId: z.string().nullable().optional(),\n  agentId: z.string().optional(),\n  userId: z.string().optional(),\n});\n\nconst ChatResponseSchema = z.object({\n  success: z.boolean(),\n  message: z.string(),\n  agentName: z.string(),\n  history: z.array(z.any()),\n  threadId: z.string().optional(),\n  lastAgentId: z.string().optional(),\n  toolCalls: z.array(z.object({\n    name: z.string(),\n    arguments: z.any(),\n    result: z.any().optional(),\n  })).optional(),\n});\n\nexport async function POST(request: NextRequest) {\n  try {\n    const body = await request.json();\n    const { message, threadId, agentId, userId } = ChatRequestSchema.parse(body);\n\n    // Initialize Convex client\n    const convex = new ConvexHttpClient(process.env.NEXT_PUBLIC_CONVEX_URL!);\n\n    // Determine which agent to start with\n    let currentAgent = hermesAgent; // Default to Hermes\n    if (agentId === 'hermes') {\n      currentAgent = hermesAgent;\n    } else if (agentId === 'steve') {\n      currentAgent = steveAgent;\n    } else if (agentId === 'atlas') {\n      currentAgent = atlasAgent;\n    } else if (agentId === 'juno') {\n      currentAgent = junoAgent;\n    } else if (agentId === 'dope-admin') {\n      currentAgent = dopeAdminAgent;\n    }\n\n    // Get or create thread - SIMPLE VERSION\n    let savedMessages: any[] = [];\n    let currentThreadId = threadId || null;\n    \n    if (currentThreadId) {\n      // Load existing thread\n      const existingThread = await convex.query(api.threads.getThread, { \n        threadId: currentThreadId \n      });\n      if (existingThread) {\n        savedMessages = existingThread.history || [];\n      }\n    } else {\n      // Create new thread\n      currentThreadId = `thread_${Date.now()}_${Math.random().toString(36).substring(2, 11)}`;\n    }\n\n    // Build proper conversation thread with history for context\n    const conversationThread: AgentInputItem[] = [];\n    \n    // Add previous messages from history\n    for (const msg of savedMessages) {\n      if (msg.role === 'user') {\n        conversationThread.push(user(extractContent(msg.content)));\n      } else if (msg.role === 'assistant') {\n        // Add assistant messages as system messages to provide context\n        conversationThread.push({\n          role: 'system',\n          content: `Previous assistant response: ${extractContent(msg.content)}`\n        });\n      }\n    }\n    \n    // Add the new user message\n    conversationThread.push(user(message));\n\n    // Connect MCP server, run, then close\n    await sequentialThinkingServer.connect();\n\n    const result = await withTrace('Chat Session', async () => {\n      return await run(currentAgent, conversationThread, {\n        maxTurns: 20, // Limit turns to prevent infinite loops\n      });\n    });\n    \n    await sequentialThinkingServer.close();\n\n    // Extract tool calls from the result history\n    const toolCalls: Array<{name: string, arguments: any, result?: any}> = [];\n    if (result.history) {\n      const callResults = new Map();\n      \n      // First pass: collect function call results\n      for (const item of result.history) {\n        if (item.type === 'function_call_result') {\n          callResults.set(item.callId, item.output);\n        }\n      }\n      \n      // Second pass: collect function calls and match with results\n      for (const item of result.history) {\n        if (item.type === 'function_call') {\n          toolCalls.push({\n            name: item.name,\n            arguments: typeof item.arguments === 'string' ? JSON.parse(item.arguments) : item.arguments,\n            result: callResults.get(item.callId)\n          });\n        }\n        // Handle hosted tool calls (like web search)\n        else if (item.type === 'hosted_tool_call') {\n          toolCalls.push({\n            name: item.name,\n            arguments: item.providerData?.action || {},\n            result: item.status === 'completed' ? 'Search completed successfully' : item.status\n          });\n        }\n      }\n    }\n\n    // Create simple message history for saving\n    const messagesToSave = [\n      ...savedMessages,\n      {\n        role: 'user',\n        content: message,\n        timestamp: Date.now(),\n        agentName: 'user'\n      },\n      {\n        role: 'assistant', \n        content: result.finalOutput || 'No response generated',\n        timestamp: Date.now(),\n        agentName: result.lastAgent?.name || currentAgent.name,\n        toolCalls: toolCalls.length > 0 ? toolCalls : undefined\n      }\n    ];\n\n    // Save to Convex - SIMPLE VERSION\n    if (currentThreadId) {\n      if (savedMessages.length === 0) {\n        // Create new thread\n        await convex.mutation(api.threads.createThread, {\n          threadId: currentThreadId,\n          userId: userId,\n          agentId: result.lastAgent?.name.toLowerCase().replace(/\\s+/g, '-') || agentId || 'hermes',\n          title: \"New Chat\",\n          history: messagesToSave,\n        });\n      } else {\n        // Update existing thread\n        await convex.mutation(api.threads.updateThread, {\n          threadId: currentThreadId,\n          agentId: result.lastAgent?.name.toLowerCase().replace(/\\s+/g, '-') || agentId,\n          title: \"Chat\", // Keep it simple\n          history: messagesToSave,\n        });\n      }\n    }\n\n    const response = ChatResponseSchema.parse({\n      success: true,\n      message: result.finalOutput || 'No response generated',\n      agentName: result.lastAgent?.name || currentAgent.name,\n      history: messagesToSave,\n      threadId: currentThreadId,\n      lastAgentId: result.lastAgent?.name.toLowerCase().replace(/\\s+/g, '-') || agentId,\n      toolCalls: toolCalls.length > 0 ? toolCalls : undefined,\n    });\n\n    return NextResponse.json(response);\n\n  } catch (error) {\n    console.error('Chat API error:', error);\n    \n    return NextResponse.json(\n      {\n        success: false,\n        error: error instanceof Error ? error.message : 'Unknown error occurred',\n        message: 'Sorry, I encountered an error processing your request.',\n        agentName: 'System',\n        history: [],\n      },\n      { status: 500 }\n    );\n  }\n}\n\n// GET endpoint to retrieve available agents\nexport async function GET() {\n  try {\n    const agents = [\n      {\n        id: 'hermes',\n        name: 'Hermes',\n        description: 'Proposal Generator - Utilizes templates and company information to generate tailored proposals',\n        capabilities: ['web-search', 'proposal-generation', 'client-analysis', 'sales-support'],\n        tools: ['list_templates', 'email_creation_by_website_and_template', 'list_how_to_generate_a_proposal', 'pinecone_company_knowledge_semantic_search', 'pinecone_email_templates_semantic_search', 'pinecone_faq_data_semantic_search'],\n      },\n      {\n        id: 'steve',\n        name: 'Steve',\n        description: 'Leadership Agent - Leverages CliftonStrengths and employee profiles for team development',\n        capabilities: ['web-search', 'team-collaboration', 'standup-facilitation', 'performance-improvement'],\n        tools: ['atlas tool', 'facilitate_standup', 'pinecone_add_transcript_data_to_index', 'pinecone_company_knowledge_semantic_search', 'pinecone_employee_data_semantic_search', 'pinecone_transcript_data_semantic_search', 'web_search'],\n      },\n      {\n        id: 'atlas',\n        name: 'Atlas',\n        description: 'Business Intelligence Agent - Conducts website analysis.',\n        capabilities: ['web-search', 'website-analysis', 'competitive-intelligence', 'strategic-recommendations'],\n        tools: ['analyze_website', 'deep_research'],\n      },\n      {\n        id: 'juno',\n        name: 'Juno',\n        description: 'Data Integration Agent - Connects to Metabase for comprehensive data analytics',\n        capabilities: ['web-search', 'data-analytics', 'metabase-integration', 'decision-support'],\n        tools: ['query_data', 'web_search'],\n      },\n      {\n        id: 'dope-admin',\n        name: 'Dope Admin',\n        description: 'Dope Marketing Admin Agent - Helps the engineer complete any tasks and is helpful overall.',\n        capabilities: ['web-search', 'admin-support'],\n        tools: ['web_search', 'pinecone_list_indexes', 'pinecone_create_index', 'pinecone_add_to_index', 'pinecone_add_employee_data_to_index', 'pinecone_add_transcript_data_to_index', 'pinecone_semantic_search'],\n      },\n    ];\n\n    return NextResponse.json({\n      success: true,\n      data: agents,\n    });\n  } catch (error) {\n    console.error('Error fetching chat agents:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to fetch agents' },\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AAAA;AAAA;AAAA;AAWA;AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AAKA,IAAA,uLAAmB,EAAC,sCAAwC;AAC5D,IAAA,0LAAsB,EAAC,sCAAwC;AAE/D,MAAM,YAAY,IAAI,+IAAS,CAAC;IAC9B,MAAM,sCAAwC;AAChD;AAEA,MAAM,SAAS,IAAI,mLAAM,CAAC;IACxB,QAAQ,sCAAwC;AAClD;AAGO,MAAM,UAAU;AAEvB,4CAA4C;AAC5C,MAAM,2BAA2B,IAAI,gLAAc,CAAC;IAClD,MAAM;IACN,aAAa;AACf;AAEA;;;;mGAImG,GAEnG,MAAM,cAAc,yKAAC,CAAC,MAAM,CAAC;IAC3B,SAAS,yKAAC,CAAC,MAAM;IACjB,MAAM,yKAAC,CAAC,MAAM;IACd,cAAc,yKAAC,CAAC,MAAM;IACtB,cAAc,yKAAC,CAAC,MAAM;IACtB,aAAa,yKAAC,CAAC,MAAM;IACrB,wBAAwB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC9C;AAGA;;;;mGAImG,GAEnG,MAAM,iBAAiB;IACrB;QACE,MAAM;QACN,aAAa;QACb,UAAU,CAAC;;;;;;;;;iBASE,CAAC;IAChB;IAEA;QACE,MAAM;QACN,aAAa;QACb,UAAU,CAAC;;;;;;;;;eASA,CAAC;IACd;IAEA;QACE,MAAM;QACN,aAAa;QACb,UAAU,CAAC;;;;;;;;;eASA,CAAC;IACd;CAED;AACD,MAAM,qBAAqB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;AAwB5B,CAAC;AACD,MAAM,YAAY,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4DnB,CAAC;AACD,MAAM,iBAAiB,CAAC;;;;;;;;;;;AAWxB,CAAC;AACD,MAAM,uBAAuB,CAAC;;;;;;;;;;;;;;;AAe9B,CAAC;AAED,+CAA+C;AAC/C,MAAM,iBAAiB,CAAC;IACtB,IAAI,OAAO,YAAY,UAAU;QAC/B,OAAO;IACT,OAAO,IAAI,WAAW,OAAO,YAAY,UAAU;QACjD,IAAI,QAAQ,IAAI,EAAE,OAAO,QAAQ,IAAI;QACrC,IAAI,QAAQ,OAAO,EAAE,OAAO,QAAQ,OAAO;QAC3C,IAAI,MAAM,OAAO,CAAC,UAAU;YAC1B,OAAO,QAAQ,GAAG,CAAC,CAAA,IACjB,OAAO,MAAM,WAAW,IAAK,EAAE,IAAI,IAAI,EAAE,OAAO,IAAI,KAAK,SAAS,CAAC,IACnE,IAAI,CAAC;QACT;QACA,OAAO,KAAK,SAAS,CAAC;IACxB;IACA,OAAO,OAAO,WAAW;AAC3B;AAEA,MAAM,4BAA4B,OAAO;IACvC,IAAI;QACF,MAAM,eAAe,CAAC;;;;IAItB,CAAC;QAED,MAAM,aAAa,CAAC;8DACsC,EAAE,aAAa;IACzE,CAAC;QAED,MAAM,WAAW,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACpD,OAAO;YACP,UAAU;gBACR;oBAAE,MAAM;oBAAU,SAAS;gBAAa;gBACxC;oBAAE,MAAM;oBAAQ,SAAS;gBAAW;aACrC;YACD,uBAAuB;YACvB,aAAa;QACf;QAEA,OAAO,SAAS,OAAO,CAAC,EAAE,EAAE,SAAS,SAAS,UAAU;IAC1D,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,wCAAwC;QACtD,qDAAqD;QACrD,MAAM,mBAAmB,aAAa,SAAS,CAAC,GAAG;QACnD,OAAO,iBAAiB,MAAM,GAAG,aAAa,MAAM,GAChD,GAAG,iBAAiB,GAAG,CAAC,GACxB;IACN;AACF;AAEA;;;;mGAImG,GAEnG,MAAM,oBAAoB,IAAA,sKAAI,EAAC;IAC7B,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC,CAAC;IACtB,SAAS,OAAO;QACd,OAAO;IACT;AACF;AACA,MAAM,wCAAwC,IAAA,sKAAI,EAAC;IACjD,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,aAAa,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACjC,cAAc,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAClC,2BAA2B,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;IAC5D;IACA,SAAS,OAAO;QAEd,MAAM,EAAE,WAAW,EAAE,YAAY,EAAE,yBAAyB,EAAE,GAAG;QAEjE,MAAM,+BAA+B,MAAM,IAAA,yKAA0B,EAAC,aAAa;QAEnF,mGAAmG;QACnG,MAAM,iCAAiC,8BAA8B;QAErE,MAAM,eAAe,CAAC;;;IAGtB,EAAE,mBAAmB;;;IAGrB,EAAE,UAAU;;;;EAId,EAAE,eAAe,GAAG,CAAC,CAAA,WAAY,CAAC,MAAM,EAAE,SAAS,IAAI,CAAC,eAAe,EAAE,SAAS,WAAW,CAAC,YAAY,EAAE,SAAS,QAAQ,EAAE,EAAE,IAAI,CAAC,QAAQ;;;mEAG7E,EAAE,aAAa,CAAC,CAAC;QAEhF,MAAM,aAAa,CAAC;;;IAGpB,EAAE,aAAa;;;IAGf,EAAE,+BAA+B;;IAEjC,EAAE,4BAA4B,CAAC;4DACyB,EAAE,eAAe,IAAI,CAAC,CAAA,WAAY,SAAS,IAAI,KAAK,4BAA4B,MAAM,GAC5I,EAAE,CAAC;;mEAE0D,EAAE,aAAa,CAAC,CAAC;QAEhF,MAAM,WAAW,MAAM,OAAO,SAAS,CAAC,KAAK,CAAC;YAC5C,OAAO;YACP,OAAO;gBACL;oBAAE,MAAM;oBAAU,SAAS;gBAAa;gBACxC;oBACE,MAAM;oBACN,SAAS;gBACX;aACD;YACD,MAAM;gBACJ,QAAQ,IAAA,4JAAa,EAAC,aAAa;YACrC;QACF;QAEA,MAAM,oBAAoB,SAAS,aAAa;QAEhD,OAAO;YACH,SAAS,mBAAmB;YAC5B,MAAM,mBAAmB;YACzB,cAAc,mBAAmB;YACjC,cAAc,mBAAmB;YACjC,aAAa,mBAAmB;YAChC,wBAAwB,mBAAmB;QAC/C;IAEF;AACF;AACA,MAAM,2BAA2B,IAAA,sKAAI,EAAC;IACpC,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC,CAAC;IACtB,SAAS,OAAO;QACd,OAAO;IACT;AACF;AAEA;;;;mGAImG,GAEnG,MAAM,wBAAwB,IAAA,sKAAI,EAAC;IACjC,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,UAAU,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAC9B,QAAQ,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;IACpD;IACA,SAAS,OAAO;QACd,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,GAAG;QAE7B,MAAM,mBAAmB;YACvB;YACA;YACA;YACA;YACA;YACA,CAAC,cAAc,EAAE,SAAS,UAAU,CAAC;YACrC,CAAC,0BAA0B,EAAE,KAAK,IAAI,CAAC,WAAW,GAAG,YAAY,CAAC;YAClE,SAAS,CAAC,4BAA4B,EAAE,OAAO,IAAI,CAAC,GAAG;YACvD;YACA;YACA;YACA;SACD;QAED,OAAO,iBAAiB,IAAI,CAAC;IAC/B;AACF;AAEA;;;;mGAImG,GAEnG,MAAM,qBAAqB,IAAA,sKAAI,EAAC;IAC9B,MAAM;IACN,aAAa,CAAC;;;;;;EAMd,CAAC;IACD,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,YAAY,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAChC,cAAc,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACpC;IACA,SAAS,OAAO;QACd,MAAM,EAAE,UAAU,EAAE,YAAY,EAAE,GAAG;QAErC,IAAI,+BAA+B;QACnC,IAAI,iCAAiC;QACrC,IAAI,kBAAkB;QAEtB,IAAI,iBAAiB,4BAA4B;YAE/C;;;;;;MAMA,GACA,kBAAkB,MAAM,IAAA,yKAA0B,EAAC,YAAY;YAE/D,OAAO;gBACL,YAAY;gBACZ,cAAc;gBACd,QAAQ,iBAAiB;gBACzB,iBAAiB,iBAAiB;YACpC;QAEF,OAAO;YAEL,+BAA+B,MAAM,IAAA,yKAA0B,EAAC,YAAY;YAC5E,iCAAiC,8BAA8B;YAE/D,OAAO;gBACL,YAAY;gBACZ,cAAc;gBACd,gCAAgC;YAClC;QAEF;IAEF;AACF;AAEA,MAAM,mBAAmB,IAAA,sKAAI,EAAC;IAC5B,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,eAAe,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACnC,YAAY,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;IACxD;IACA,SAAS,OAAO;QACd,MAAM,EAAE,aAAa,EAAE,UAAU,EAAE,GAAG;QACtC,OAAO,MAAM,IAAA,mKAAoB,EAAC,eAAe,cAAc;IACjE;AACF;AAGA;;;;mGAImG,GAEnG,MAAM,gBAAgB,IAAA,sKAAI,EAAC;IACzB,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,YAAY,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAChC,WAAW,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACjC;IACA,SAAS,OAAO;QACd,MAAM,EAAE,UAAU,EAAE,SAAS,EAAE,GAAG;QAElC,+DAA+D;QAC/D,MAAM,eAAe;YACnB,CAAC,2BAA2B,CAAC;YAC7B,CAAC,iBAAiB,EAAE,WAAW,EAAE,CAAC;YAClC,CAAC,gBAAgB,EAAE,UAAU,IAAI,CAAC;YAClC,CAAC,gBAAgB,CAAC;YAClB,CAAC,+CAA+C,CAAC;YACjD,CAAC,gDAAgD,CAAC;YAClD,CAAC,mDAAmD,CAAC;YACrD,CAAC,aAAa,CAAC;YACf,CAAC,qDAAqD,CAAC;YACvD,CAAC,4CAA4C,CAAC;YAC9C,CAAC,kDAAkD,CAAC;YACpD,CAAC,eAAe,CAAC;YACjB,CAAC,wDAAwD,CAAC;YAC1D,CAAC,mDAAmD,CAAC;YACrD,CAAC,mCAAmC,CAAC;SACtC;QAED,OAAO,aAAa,IAAI,CAAC;IAC3B;AACF;AAEA;;;;mGAImG,GAEnG,iBAAiB;AACjB,MAAM,0BAA0B,IAAA,sKAAI,EAAC;IACnC,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC,CAAC;IACtB,SAAS,OAAO;QACd,OAAO,MAAM,IAAA,8KAAuB;IACtC;AACF;AAEA,MAAM,0BAA0B,IAAA,sKAAI,EAAC;IACnC,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,WAAW,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACjC;IACA,SAAS,OAAO;QACd,MAAM,EAAE,SAAS,EAAE,GAAG;QACtB,OAAO,MAAM,IAAA,kKAAW,EAAC;IAC3B;AACF;AACA,MAAM,qCAAqC,IAAA,sKAAI,EAAC;IAC9C,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,MAAM,yKAAC,CAAC,MAAM,CAAC;YACb,cAAc,yKAAC,CAAC,MAAM,CAAC;gBACrB,YAAY,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBAChC,MAAM,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBAC1B,cAAc,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBAClC,UAAU,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBAC9B,WAAW,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBAC/B,QAAQ,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;gBAClD,gBAAgB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBACpC,OAAO,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,CAAC;gBACpC,YAAY,yKAAC,CAAC,IAAI,CAAC;oBAAC;oBAAa;oBAAe;oBAAyB;iBAAqB,EAAE,QAAQ,CAAC;gBACzG,cAAc,yKAAC,CAAC,MAAM,CAAC;oBACrB,WAAW,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM;oBAC3B,aAAa,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM;oBAC7B,sBAAsB,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM;oBACtC,kBAAkB,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM;gBACpC,GAAG,QAAQ,CAAC;gBACZ,gBAAgB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBACpC,mBAAmB,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBACvC,YAAY,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBAChC,YAAY,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,CAAC;gBACzC,cAAc,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,CAAC;gBAC3C,WAAW,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBAC/B,gBAAgB,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,CAAC;oBAC/B,OAAO,yKAAC,CAAC,MAAM;oBACf,SAAS,yKAAC,CAAC,MAAM;gBACnB,IAAI,QAAQ,CAAC;gBACb,cAAc,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;gBACxD,kBAAkB,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;YAC9D,GAAG,QAAQ,CAAC;YACZ,MAAM,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;YACzD,QAAQ,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;QACpD,GAAG,QAAQ,CAAC;IACd;IACA,SAAS,OAAO;QACd,MAAM,EAAE,IAAI,EAAE,GAAG;QACjB,OAAO,MAAM,IAAA,6KAAsB,EAAC,sBAAsB;IAC5D;AACF;AACA,MAAM,uCAAuC,IAAA,sKAAI,EAAC;IAChD,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,MAAM,yKAAC,CAAC,MAAM,CAAC;YACb,gBAAgB,yKAAC,CAAC,MAAM,CAAC;gBACvB,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;gBAC3B,aAAa,yKAAC,CAAC,IAAI,CAAC;oBAAC;oBAAa;oBAAQ;oBAAW;oBAAgB;iBAAQ,EAAE,QAAQ,GAAG,QAAQ;gBAClG,UAAU,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;gBACpD,cAAc,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,GAAG,QAAQ;gBACrD,UAAU,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ;gBACxC,YAAY,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ;gBAC1C,sBAAsB,yKAAC,CAAC,IAAI,CAAC;oBAAC;oBAAU;oBAAY;oBAAgB;iBAAa,EAAE,QAAQ,GAAG,QAAQ;gBACtG,cAAc,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,GAAG,QAAQ;gBACrD,oBAAoB,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,GAAG,QAAQ;gBAC3D,MAAM,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ;gBACpC,YAAY,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,GAAG,QAAQ;gBACnD,SAAS,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ;YACzC,GAAG,QAAQ,CAAC;YACZ,MAAM,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,GAAG,QAAQ;YAC7C,QAAQ,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ;QACxC,GAAG,QAAQ,CAAC;IACd;IACA,SAAS,OAAO;QACd,MAAM,EAAE,IAAI,EAAE,GAAG;QACjB,MAAM,KAAK,KAAK,cAAc,IAAI,CAAC;QACnC,MAAM,UAAU;YACd,gBAAgB;gBACd,OAAO,GAAG,KAAK,IAAI;gBACnB,aAAa,GAAG,WAAW,IAAI;gBAC/B,UAAU,GAAG,QAAQ,IAAI;gBACzB,cAAc,MAAM,OAAO,CAAC,GAAG,YAAY,IAAI,GAAG,YAAY,GAAI,GAAG,YAAY,IAAI;gBACrF,UAAU,GAAG,QAAQ,IAAI;gBACzB,YAAY,GAAG,UAAU,IAAI;gBAC7B,sBAAsB,GAAG,oBAAoB,IAAI;gBACjD,cAAc,MAAM,OAAO,CAAC,GAAG,YAAY,IAAI,GAAG,YAAY,GAAI,GAAG,YAAY,IAAI;gBACrF,oBAAoB,MAAM,OAAO,CAAC,GAAG,kBAAkB,IAAI,GAAG,kBAAkB,GAAI,GAAG,kBAAkB,IAAI;gBAC7G,MAAM,GAAG,IAAI,IAAI;gBACjB,YAAY,MAAM,OAAO,CAAC,GAAG,UAAU,IAAI,GAAG,UAAU,GAAI,GAAG,UAAU,IAAI;gBAC7E,SAAS,GAAG,OAAO,IAAI;YACzB;YACA,MAAM,MAAM,OAAO,CAAC,KAAK,IAAI,IAAI,KAAK,IAAI,GAAI,KAAK,IAAI,IAAI;YAC3D,QAAQ,KAAK,MAAM,IAAI;QACzB;QAEA,OAAO,MAAM,IAAA,+KAAwB,EAAC,wBAAwB;IAChE;AACF;AAEA,wBAAwB;AACxB,MAAM,yBAAyB,IAAA,sKAAI,EAAC;IAClC,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,WAAW,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC,6EAA6E,OAAO,MAAM,CAAC,wJAAW,EAAE,IAAI,CAAC;QAC5I,MAAM,yKAAC,CAAC,MAAM,CAAC;YACb,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;YAC3B,SAAS,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;YAC7B,wFAAwF;YACxF,UAAU,yKAAC,CACR,MAAM,CACL,yKAAC,CAAC,MAAM,IACR,yKAAC,CAAC,KAAK,CAAC;gBACN,yKAAC,CAAC,MAAM;gBACR,yKAAC,CAAC,MAAM;gBACR,yKAAC,CAAC,OAAO;gBACT,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM;gBAChB,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM;gBAChB,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,OAAO;aAClB,GAEF,QAAQ,GACR,QAAQ,GACR,QAAQ,CAAC;QACd,GAAG,QAAQ,CAAC;IACd;IACA,SAAS,OAAO;QACd,MAAM,EAAE,SAAS,EAAE,IAAI,EAAE,GAAG;QAC5B,OAAO,MAAM,IAAA,iKAAU,EAAC,WAAW;YACjC,OAAO,KAAK,KAAK;YACjB,SAAS,KAAK,OAAO;YACrB,UAAU,KAAK,QAAQ,IAAI;QAC7B;IACF;AACF;AAEA,gCAAgC;AAChC,MAAM,6BAA6B,IAAA,sKAAI,EAAC;IACtC,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,WAAW,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAC/B,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAC3B,MAAM,yKAAC,CAAC,MAAM,GAAG,GAAG,GAAG,QAAQ,GAAG,GAAG,CAAC,MAAM,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;QAC3E,QAAQ,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,IAAI,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;IAC7D;IACA,SAAS,OAAO;QACd,MAAM,EAAE,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,MAAM,EAAE,GAAG;QAC3C,MAAM,WAAW,MAAM,IAAA,qKAAc,EAAC,WAAW;YAC/C;YACA,MAAM,QAAQ;YACd,WAAW;YACX,QAAQ,UAAU;QACpB;QACA,OAAO;IACT;AACF;AAEA,8CAA8C;AAC9C,MAAM,6CAA6C,IAAA,sKAAI,EAAC;IACtD,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC7B;IACA,SAAS,OAAO;QACd,MAAM,EAAE,KAAK,EAAE,GAAG;QAClB,OAAO,MAAM,IAAA,qKAAc,EAAC,0BAA0B;YAAE;YAAO,MAAM;YAAG,WAAW;YAAe,QAAQ;QAAU;IACtH;AACF;AACA,0CAA0C;AAC1C,MAAM,yCAAyC,IAAA,sKAAI,EAAC;IAClD,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC7B;IACA,SAAS,OAAO;QACd,MAAM,EAAE,KAAK,EAAE,GAAG;QAClB,OAAO,MAAM,IAAA,qKAAc,EAAC,sBAAsB;YAAE;YAAO,MAAM;YAAG,WAAW;YAAe,QAAQ;QAAU;IAClH;AACF;AACA,4CAA4C;AAC5C,MAAM,2CAA2C,IAAA,sKAAI,EAAC;IACpD,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC7B;IACA,SAAS,OAAO;QACd,MAAM,EAAE,KAAK,EAAE,GAAG;QAClB,OAAO,MAAM,IAAA,qKAAc,EAAC,wBAAwB;YAAE;YAAO,MAAM;YAAG,WAAW;YAAe,QAAQ;QAAU;IACpH;AACF;AACA,4CAA4C;AAC5C,MAAM,2CAA2C,IAAA,sKAAI,EAAC;IACpD,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC7B;IACA,SAAS,OAAO;QACd,MAAM,EAAE,KAAK,EAAE,GAAG;QAClB,OAAO,MAAM,IAAA,qKAAc,EAAC,wBAAwB;YAAE;YAAO,MAAM;YAAG,WAAW;YAAe,QAAQ;QAAU;IACpH;AACF;AACA,qCAAqC;AACrC,MAAM,oCAAoC,IAAA,sKAAI,EAAC;IAC7C,MAAM;IACN,aAAa;IACb,YAAY,yKAAC,CAAC,MAAM,CAAC;QACnB,OAAO,yKAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC7B;IACA,SAAS,OAAO;QACd,MAAM,EAAE,KAAK,EAAE,GAAG;QAClB,OAAO,MAAM,IAAA,qKAAc,EAAC,iBAAiB;YAAE;YAAO,MAAM;YAAG,WAAW;YAAe,QAAQ;QAAU;IAC7G;AACF;AAGA;;;;mGAImG,GAEnG,MAAM,aAAa,IAAI,uKAAK,CAAC;IAC3B,MAAM;IACN,cAAc,CAAC;;;;;;;;;;;;;;2HAc0G,CAAC;IAC1H,oBAAoB;IACpB,OAAO;QAAC;QAAoB;KAAiB;IAC7C,YAAY;QAAC;KAAyB;IACtC,OAAO;IACP,eAAe;QACb,mBAAmB;IACrB;AACF;AACA,kBAAkB;AAClB,MAAM,YAAY,WAAW,MAAM,CAAC;IAClC,UAAU;IACV,iBAAiB;AACnB;AAEA,MAAM,cAAc,IAAI,uKAAK,CAAC;IAC5B,MAAM;IACN,cAAc,CAAC;;IAEb,EAAE,mBAAmB;;IAErB,EAAE,UAAU;;;;;;;;;;;;IAYZ,EAAE,qBAAqB;;;;;IAKvB,EAAE,eAAe,GAAG,CAAC,CAAA,WAAY,CAAC,EAAE,EAAE,SAAS,IAAI,CAAC,EAAE,EAAE,SAAS,WAAW,EAAE,EAAE,IAAI,CAAC,MAAM;;EAE7F,CAAC;IACD,oBAAoB;IACpB,OAAO;QAAC;QAAmB;QAAuC;QAA0B;QAA4C;QAA0C;QAA0C;KAAkC;IAC9P,YAAY;QAAC;KAAyB;IACtC,OAAO;IACP,eAAe;QACb,mBAAmB;IACrB;AACF;AAEA,MAAM,aAAa,IAAI,uKAAK,CAAC;IAC3B,MAAM;IACN,cAAc,CAAC;;;;;;;;;;;;;;;EAef,CAAC;IACD,oBAAoB;IACpB,OAAO;QAAC;QAAW;QAAuB;QAAsC;QAA4C;QAAwC;QAA0C,IAAA,iLAAa;KAAG;IAC9N,YAAY;QAAC;KAAyB;IACtC,OAAO;IACP,eAAe;QACb,mBAAmB;IACrB;AACF;AAEA,MAAM,YAAY,IAAI,uKAAK,CAAC;IAC1B,MAAM;IACN,cAAc,CAAC;;;;;;;kLAOiK,CAAC;IACjL,oBAAoB;IACpB,OAAO;QAAC;QAAe,IAAA,iLAAa;KAAG;IACvC,YAAY;QAAC;KAAyB;IACtC,OAAO;IACP,eAAe;QACb,mBAAmB;IACrB;AACF;AAEA,MAAM,iBAAiB,IAAI,uKAAK,CAAC;IAC/B,MAAM;IACN,cAAc,CAAC;EACf,CAAC;IACD,oBAAoB;IACpB,OAAO;QAAC,IAAA,iLAAa;QAAI;QAAyB;QAAyB;QAAwB;QAAoC;QAAsC;KAA2B;IACxM,YAAY;QAAC;KAAyB;IACtC,OAAO;IACP,eAAe;QACb,mBAAmB;IACrB;AACF;AAEA,iCAAiC;AACjC,YAAY,QAAQ,GAAG;IAAC;IAAY;IAAY;CAAU;AAC1D,WAAW,QAAQ,GAAG;IAAC;IAAa;IAAY;CAAU;AAC1D,WAAW,QAAQ,GAAG;IAAC;IAAa;IAAY;CAAU;AAC1D,UAAU,QAAQ,GAAG;IAAC;IAAa;IAAY;CAAW;AAG1D,2BAA2B;AAC3B,MAAM,oBAAoB,yKAAC,CAAC,MAAM,CAAC;IACjC,SAAS,yKAAC,CAAC,MAAM;IACjB,UAAU,yKAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ;IACxC,SAAS,yKAAC,CAAC,MAAM,GAAG,QAAQ;IAC5B,QAAQ,yKAAC,CAAC,MAAM,GAAG,QAAQ;AAC7B;AAEA,MAAM,qBAAqB,yKAAC,CAAC,MAAM,CAAC;IAClC,SAAS,yKAAC,CAAC,OAAO;IAClB,SAAS,yKAAC,CAAC,MAAM;IACjB,WAAW,yKAAC,CAAC,MAAM;IACnB,SAAS,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,GAAG;IACtB,UAAU,yKAAC,CAAC,MAAM,GAAG,QAAQ;IAC7B,aAAa,yKAAC,CAAC,MAAM,GAAG,QAAQ;IAChC,WAAW,yKAAC,CAAC,KAAK,CAAC,yKAAC,CAAC,MAAM,CAAC;QAC1B,MAAM,yKAAC,CAAC,MAAM;QACd,WAAW,yKAAC,CAAC,GAAG;QAChB,QAAQ,yKAAC,CAAC,GAAG,GAAG,QAAQ;IAC1B,IAAI,QAAQ;AACd;AAEO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,MAAM,EAAE,OAAO,EAAE,QAAQ,EAAE,OAAO,EAAE,MAAM,EAAE,GAAG,kBAAkB,KAAK,CAAC;QAEvE,2BAA2B;QAC3B,MAAM,SAAS,IAAI,qLAAgB;QAEnC,sCAAsC;QACtC,IAAI,eAAe,aAAa,oBAAoB;QACpD,IAAI,YAAY,UAAU;YACxB,eAAe;QACjB,OAAO,IAAI,YAAY,SAAS;YAC9B,eAAe;QACjB,OAAO,IAAI,YAAY,SAAS;YAC9B,eAAe;QACjB,OAAO,IAAI,YAAY,QAAQ;YAC7B,eAAe;QACjB,OAAO,IAAI,YAAY,cAAc;YACnC,eAAe;QACjB;QAEA,wCAAwC;QACxC,IAAI,gBAAuB,EAAE;QAC7B,IAAI,kBAAkB,YAAY;QAElC,IAAI,iBAAiB;YACnB,uBAAuB;YACvB,MAAM,iBAAiB,MAAM,OAAO,KAAK,CAAC,mJAAG,CAAC,OAAO,CAAC,SAAS,EAAE;gBAC/D,UAAU;YACZ;YACA,IAAI,gBAAgB;gBAClB,gBAAgB,eAAe,OAAO,IAAI,EAAE;YAC9C;QACF,OAAO;YACL,oBAAoB;YACpB,kBAAkB,CAAC,OAAO,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,SAAS,CAAC,GAAG,KAAK;QACzF;QAEA,4DAA4D;QAC5D,MAAM,qBAAuC,EAAE;QAE/C,qCAAqC;QACrC,KAAK,MAAM,OAAO,cAAe;YAC/B,IAAI,IAAI,IAAI,KAAK,QAAQ;gBACvB,mBAAmB,IAAI,CAAC,IAAA,sKAAI,EAAC,eAAe,IAAI,OAAO;YACzD,OAAO,IAAI,IAAI,IAAI,KAAK,aAAa;gBACnC,+DAA+D;gBAC/D,mBAAmB,IAAI,CAAC;oBACtB,MAAM;oBACN,SAAS,CAAC,6BAA6B,EAAE,eAAe,IAAI,OAAO,GAAG;gBACxE;YACF;QACF;QAEA,2BAA2B;QAC3B,mBAAmB,IAAI,CAAC,IAAA,sKAAI,EAAC;QAE7B,sCAAsC;QACtC,MAAM,yBAAyB,OAAO;QAEtC,MAAM,SAAS,MAAM,IAAA,sLAAS,EAAC,gBAAgB;YAC7C,OAAO,MAAM,IAAA,qKAAG,EAAC,cAAc,oBAAoB;gBACjD,UAAU;YACZ;QACF;QAEA,MAAM,yBAAyB,KAAK;QAEpC,6CAA6C;QAC7C,MAAM,YAAiE,EAAE;QACzE,IAAI,OAAO,OAAO,EAAE;YAClB,MAAM,cAAc,IAAI;YAExB,4CAA4C;YAC5C,KAAK,MAAM,QAAQ,OAAO,OAAO,CAAE;gBACjC,IAAI,KAAK,IAAI,KAAK,wBAAwB;oBACxC,YAAY,GAAG,CAAC,KAAK,MAAM,EAAE,KAAK,MAAM;gBAC1C;YACF;YAEA,6DAA6D;YAC7D,KAAK,MAAM,QAAQ,OAAO,OAAO,CAAE;gBACjC,IAAI,KAAK,IAAI,KAAK,iBAAiB;oBACjC,UAAU,IAAI,CAAC;wBACb,MAAM,KAAK,IAAI;wBACf,WAAW,OAAO,KAAK,SAAS,KAAK,WAAW,KAAK,KAAK,CAAC,KAAK,SAAS,IAAI,KAAK,SAAS;wBAC3F,QAAQ,YAAY,GAAG,CAAC,KAAK,MAAM;oBACrC;gBACF,OAEK,IAAI,KAAK,IAAI,KAAK,oBAAoB;oBACzC,UAAU,IAAI,CAAC;wBACb,MAAM,KAAK,IAAI;wBACf,WAAW,KAAK,YAAY,EAAE,UAAU,CAAC;wBACzC,QAAQ,KAAK,MAAM,KAAK,cAAc,kCAAkC,KAAK,MAAM;oBACrF;gBACF;YACF;QACF;QAEA,2CAA2C;QAC3C,MAAM,iBAAiB;eAClB;YACH;gBACE,MAAM;gBACN,SAAS;gBACT,WAAW,KAAK,GAAG;gBACnB,WAAW;YACb;YACA;gBACE,MAAM;gBACN,SAAS,OAAO,WAAW,IAAI;gBAC/B,WAAW,KAAK,GAAG;gBACnB,WAAW,OAAO,SAAS,EAAE,QAAQ,aAAa,IAAI;gBACtD,WAAW,UAAU,MAAM,GAAG,IAAI,YAAY;YAChD;SACD;QAED,kCAAkC;QAClC,IAAI,iBAAiB;YACnB,IAAI,cAAc,MAAM,KAAK,GAAG;gBAC9B,oBAAoB;gBACpB,MAAM,OAAO,QAAQ,CAAC,mJAAG,CAAC,OAAO,CAAC,YAAY,EAAE;oBAC9C,UAAU;oBACV,QAAQ;oBACR,SAAS,OAAO,SAAS,EAAE,KAAK,cAAc,QAAQ,QAAQ,QAAQ,WAAW;oBACjF,OAAO;oBACP,SAAS;gBACX;YACF,OAAO;gBACL,yBAAyB;gBACzB,MAAM,OAAO,QAAQ,CAAC,mJAAG,CAAC,OAAO,CAAC,YAAY,EAAE;oBAC9C,UAAU;oBACV,SAAS,OAAO,SAAS,EAAE,KAAK,cAAc,QAAQ,QAAQ,QAAQ;oBACtE,OAAO;oBACP,SAAS;gBACX;YACF;QACF;QAEA,MAAM,WAAW,mBAAmB,KAAK,CAAC;YACxC,SAAS;YACT,SAAS,OAAO,WAAW,IAAI;YAC/B,WAAW,OAAO,SAAS,EAAE,QAAQ,aAAa,IAAI;YACtD,SAAS;YACT,UAAU;YACV,aAAa,OAAO,SAAS,EAAE,KAAK,cAAc,QAAQ,QAAQ,QAAQ;YAC1E,WAAW,UAAU,MAAM,GAAG,IAAI,YAAY;QAChD;QAEA,OAAO,gJAAY,CAAC,IAAI,CAAC;IAE3B,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,mBAAmB;QAEjC,OAAO,gJAAY,CAAC,IAAI,CACtB;YACE,SAAS;YACT,OAAO,iBAAiB,QAAQ,MAAM,OAAO,GAAG;YAChD,SAAS;YACT,WAAW;YACX,SAAS,EAAE;QACb,GACA;YAAE,QAAQ;QAAI;IAElB;AACF;AAGO,eAAe;IACpB,IAAI;QACF,MAAM,SAAS;YACb;gBACE,IAAI;gBACJ,MAAM;gBACN,aAAa;gBACb,cAAc;oBAAC;oBAAc;oBAAuB;oBAAmB;iBAAgB;gBACvF,OAAO;oBAAC;oBAAkB;oBAA0C;oBAAmC;oBAA8C;oBAA4C;iBAAoC;YACvO;YACA;gBACE,IAAI;gBACJ,MAAM;gBACN,aAAa;gBACb,cAAc;oBAAC;oBAAc;oBAAsB;oBAAwB;iBAA0B;gBACrG,OAAO;oBAAC;oBAAc;oBAAsB;oBAAyC;oBAA8C;oBAA0C;oBAA4C;iBAAa;YACxO;YACA;gBACE,IAAI;gBACJ,MAAM;gBACN,aAAa;gBACb,cAAc;oBAAC;oBAAc;oBAAoB;oBAA4B;iBAA4B;gBACzG,OAAO;oBAAC;oBAAmB;iBAAgB;YAC7C;YACA;gBACE,IAAI;gBACJ,MAAM;gBACN,aAAa;gBACb,cAAc;oBAAC;oBAAc;oBAAkB;oBAAwB;iBAAmB;gBAC1F,OAAO;oBAAC;oBAAc;iBAAa;YACrC;YACA;gBACE,IAAI;gBACJ,MAAM;gBACN,aAAa;gBACb,cAAc;oBAAC;oBAAc;iBAAgB;gBAC7C,OAAO;oBAAC;oBAAc;oBAAyB;oBAAyB;oBAAyB;oBAAuC;oBAAyC;iBAA2B;YAC9M;SACD;QAED,OAAO,gJAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,MAAM;QACR;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,+BAA+B;QAC7C,OAAO,gJAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAAyB,GAClD;YAAE,QAAQ;QAAI;IAElB;AACF","debugId":null}}]
}